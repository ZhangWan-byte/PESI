{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e5d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from Bio import Align\n",
    "\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a75139",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mFTransformer\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "model = FTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3211a5a",
   "metadata": {},
   "source": [
    "# FrameSlidingTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "763cf72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 3, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frame_slice(x, frame_size=6):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, L, E)\n",
    "        frame_size: size of frames\n",
    "    Returns:\n",
    "        frames: (num_frames*B, frame_size, C)\n",
    "    \"\"\"\n",
    "    B, L, E = x.shape\n",
    "    x = x.view(B, L // frame_size, frame_size, E)\n",
    "    frames = x.contiguous().view(-1, frame_size, E)\n",
    "\n",
    "    return frames\n",
    "\n",
    "x = torch.ones(16, 72, 32)\n",
    "\n",
    "x1 = frame_slice(x, frame_size=3)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d0595f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 71, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, L, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83267056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L // frame_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a751cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35328, 36352)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*23*3*32, 16*71*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db8ef309",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16, 23, 3, 32]' is invalid for input of size 36352",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m frame_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      3\u001b[0m B, L, E \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 4\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mframe_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m x1\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[16, 23, 3, 32]' is invalid for input of size 36352"
     ]
    }
   ],
   "source": [
    "frame_size = 3\n",
    "\n",
    "B, L, E = x.shape\n",
    "x1 = x.view(B, L // frame_size, frame_size, E)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b4c23",
   "metadata": {},
   "source": [
    "# SequenceEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6587cb9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceEncoder(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (seq_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequenceEncoder(seq_encoder_type=\"transformer\", num_layers=2, embed_size=64, hidden=512, dropout=0, nhead=4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb7a32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 48, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer\n",
    "x = torch.ones(16, 48, 64)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01625214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 48, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm\n",
    "x = torch.ones(16, 48, 64)\n",
    "model(x)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af17f63",
   "metadata": {},
   "source": [
    "# SetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c064395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params:  506721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SetModel(\n",
       "  (embedding): Embedding(27, 32)\n",
       "  (seq_encoder): SequenceEncoder(\n",
       "    (pos_encoder): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (seq_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (para_enc): Sequential(\n",
       "    (0): ISAB(\n",
       "      (mab0): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mab1): MAB(\n",
       "        (fc_q): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ISAB(\n",
       "      (mab0): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mab1): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (para_dec): Sequential(\n",
       "    (0): PMA(\n",
       "      (mab): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SAB(\n",
       "      (mab): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): SAB(\n",
       "      (mab): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (epi_enc): Sequential(\n",
       "    (0): ISAB(\n",
       "      (mab0): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mab1): MAB(\n",
       "        (fc_q): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ISAB(\n",
       "      (mab0): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mab1): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (epi_dec): Sequential(\n",
       "    (0): PMA(\n",
       "      (mab): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SAB(\n",
       "      (mab): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): SAB(\n",
       "      (mab): MAB(\n",
       "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (co_attn): CoAttention(\n",
       "    (linear_a): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (linear_b): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = 32\n",
    "hidden = 64\n",
    "\n",
    "model = SetModel(embed_size=embed_size, \n",
    "                 hidden=hidden, \n",
    "                 num_layers=2, \n",
    "                 dropout=0.1, \n",
    "                 k4kmer=5, \n",
    "                 use_pretrain=False, \n",
    "                 use_coattn=True, \n",
    "                 seq_encoder_type=\"transformer\", \n",
    "                 num_heads=4, \n",
    "                 num_inds=6, \n",
    "                 num_outputs=6, \n",
    "                 ln=False).cuda()\n",
    "\n",
    "print(\"total params: \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc63e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(12, 5, 32)\n",
    "y = torch.mean(x, dim=1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c52683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 32])\n",
      "torch.Size([12, 5, 32])\n",
      "torch.Size([12, 5, 32])\n",
      "after mean  torch.Size([12, 32])\n",
      "torch.Size([3, 4, 32])\n",
      "torch.Size([3, 6, 32])\n",
      "torch.Size([3, 6, 32]) torch.Size([3, 6, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4661],\n",
       "         [0.4661],\n",
       "         [0.4671]], device='cuda:0', grad_fn=<SigmoidBackward0>),\n",
       " torch.Size([3, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para = [\"+ABCD-##\", \"+ABCD-##\", \"+ABCD-##\"]\n",
    "epi = [\"+AD-##\", \"+AD-##\", \"+AD-##\"]\n",
    "\n",
    "out = model(para, epi)\n",
    "out, out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012baed5",
   "metadata": {},
   "source": [
    "# transformerencoder(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9917a4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=4, batch_first=True)\n",
    "seq_encoder = nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=2)\n",
    "seq_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7a80b",
   "metadata": {},
   "source": [
    "# kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9463a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmer_embed(seqs, k=3):\n",
    "    ngram_li = []\n",
    "    for seq in seqs:\n",
    "        ngram = [seq[i:i+k, :] for i in range(len(seq)-k+1)]\n",
    "        ngram_li.append(torch.stack(ngram, dim=0))\n",
    "    \n",
    "    return torch.vstack(ngram_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c43dc33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([736, 3, 32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(16, 48, 32)\n",
    "\n",
    "y = kmer_embed(x, k=3)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd117f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+AB', 'ABC', 'BCD', 'CDE', 'DEF', 'EFG', 'FG-', 'G-#', '-##']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kmer(seq, k=3):\n",
    "    ngram = [seq[i:i+k] for i in range(len(seq)-k+1)]\n",
    "    return ngram\n",
    "\n",
    "s = \"+ABCDEFG-##\"\n",
    "kmer(s, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0a3aaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.ones(2,3,4)\n",
    "kmer(s, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, seq, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "25db6ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2.0000, 2.0000, 2.0000],\n",
       "          [3.0000, 3.0000, 3.0000],\n",
       "          [4.0000, 4.0000, 4.0000]],\n",
       " \n",
       "         [[2.6667, 2.6667, 2.6667],\n",
       "          [2.0000, 2.0000, 2.0000],\n",
       "          [3.0000, 3.0000, 3.0000]]]),\n",
       " torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kmer_embed(seqs, k=3):\n",
    "    ngram_li = []\n",
    "    for seq in seqs:\n",
    "        ngram = [torch.mean(seq[i:i+k, :], dim=0) for i in range(len(seq)-k+1)]\n",
    "        ngram_li.append(torch.vstack(ngram))\n",
    "\n",
    "    return torch.stack(ngram_li)\n",
    "\n",
    "seqs = torch.tensor(\n",
    "        [[[1., 1., 1.],\n",
    "         [2., 2., 2.],\n",
    "         [3., 3., 3.],\n",
    "         [4., 4., 4.],\n",
    "         [5., 5., 5.]],\n",
    "\n",
    "        [[5., 5., 5.],\n",
    "         [1., 1., 1.],\n",
    "         [2., 2., 2.],\n",
    "         [3., 3., 3.],\n",
    "         [4., 4., 4.]]])\n",
    "\n",
    "ngram_li = []\n",
    "for seq in seqs:\n",
    "    ngram = [torch.mean(seq[i:i+k, :], dim=0) for i in range(len(seq)-k+1)]\n",
    "    ngram_li.append(torch.vstack(ngram))\n",
    "\n",
    "final = torch.stack(ngram_li)\n",
    "final, final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64bfa33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2.0000, 2.0000, 2.0000],\n",
       "          [3.0000, 3.0000, 3.0000],\n",
       "          [4.0000, 4.0000, 4.0000]],\n",
       " \n",
       "         [[2.6667, 2.6667, 2.6667],\n",
       "          [2.0000, 2.0000, 2.0000],\n",
       "          [3.0000, 3.0000, 3.0000]]]),\n",
       " torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = kmer_embed(seqs, k=3)\n",
    "res, res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e636fc",
   "metadata": {},
   "source": [
    "# align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "820eba19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"GGSISSGDSY/IYYSGST/ARHVGDLRVNDAFDI/SSNIGNNF/DSD/GTWDRSLSVVV\"\n",
    "query = \"GGSISSGDSY/IYYSGST/ARHVGDLRVNDAFDI/SSNIGNNF/DSD/GTWDRSLSVVV\"\n",
    "\n",
    "aligner = Align.PairwiseAligner()\n",
    "aligner = Align.PairwiseAligner(match_score=1.0)\n",
    "\n",
    "score = aligner.score(target, query)\n",
    "score = score / max(len(target), len(query))\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3e458",
   "metadata": {},
   "source": [
    "# how to get attn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47cdcd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Transformer()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d58bfd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1536, 512]),\n",
       " tensor([[ 0.0470, -0.0028,  0.0163,  ..., -0.0414,  0.0355, -0.0227],\n",
       "         [ 0.0279,  0.0492,  0.0412,  ...,  0.0506, -0.0014, -0.0139],\n",
       "         [ 0.0475,  0.0345,  0.0353,  ...,  0.0470, -0.0176, -0.0121],\n",
       "         ...,\n",
       "         [-0.0519, -0.0491,  0.0292,  ...,  0.0364, -0.0531, -0.0331],\n",
       "         [-0.0325,  0.0164,  0.0195,  ..., -0.0243, -0.0272, -0.0313],\n",
       "         [-0.0150,  0.0301, -0.0027,  ...,  0.0330, -0.0533, -0.0485]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layers[-1].state_dict()['self_attn.in_proj_weight'].shape, model.encoder.layers[-1].state_dict()['self_attn.in_proj_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d085dd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 512]),\n",
       " tensor([[ 0.0727,  0.0576,  0.0258,  ...,  0.0696,  0.0730, -0.0514],\n",
       "         [-0.0191, -0.0108, -0.0535,  ...,  0.0299, -0.0091,  0.0592],\n",
       "         [ 0.0610, -0.0025, -0.0308,  ..., -0.0552, -0.0339, -0.0194],\n",
       "         ...,\n",
       "         [ 0.0689, -0.0239, -0.0136,  ..., -0.0097, -0.0262, -0.0103],\n",
       "         [ 0.0089, -0.0052, -0.0376,  ...,  0.0385, -0.0002, -0.0738],\n",
       "         [-0.0671, -0.0263, -0.0067,  ...,  0.0348, -0.0179,  0.0467]]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.layers[-1].state_dict()['self_attn.out_proj.weight'].shape, model.decoder.layers[-1].state_dict()['self_attn.out_proj.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06030e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1536, 512]),\n",
       " tensor([[ 0.0138,  0.0402,  0.0142,  ...,  0.0350, -0.0382,  0.0134],\n",
       "         [ 0.0315, -0.0208, -0.0037,  ...,  0.0329,  0.0324,  0.0524],\n",
       "         [ 0.0132, -0.0481, -0.0317,  ..., -0.0450, -0.0170, -0.0525],\n",
       "         ...,\n",
       "         [ 0.0151,  0.0279,  0.0342,  ...,  0.0286, -0.0049, -0.0132],\n",
       "         [ 0.0532, -0.0446, -0.0320,  ..., -0.0411,  0.0289, -0.0172],\n",
       "         [ 0.0206,  0.0100,  0.0536,  ..., -0.0281, -0.0387,  0.0047]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.layers[-1].state_dict()['self_attn.in_proj_weight'].shape, model.decoder.layers[-1].state_dict()['self_attn.in_proj_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4be15f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1536, 512]),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0138,  0.0402,  0.0142,  ...,  0.0350, -0.0382,  0.0134],\n",
       "         [ 0.0315, -0.0208, -0.0037,  ...,  0.0329,  0.0324,  0.0524],\n",
       "         [ 0.0132, -0.0481, -0.0317,  ..., -0.0450, -0.0170, -0.0525],\n",
       "         ...,\n",
       "         [ 0.0151,  0.0279,  0.0342,  ...,  0.0286, -0.0049, -0.0132],\n",
       "         [ 0.0532, -0.0446, -0.0320,  ..., -0.0411,  0.0289, -0.0172],\n",
       "         [ 0.0206,  0.0100,  0.0536,  ..., -0.0281, -0.0387,  0.0047]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.layers[-1].self_attn.in_proj_weight.shape, model.decoder.layers[-1].self_attn.in_proj_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "754191b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_qkv_same_embed_dim',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_reset_parameters',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'add_zero_attn',\n",
       " 'apply',\n",
       " 'batch_first',\n",
       " 'bfloat16',\n",
       " 'bias_k',\n",
       " 'bias_v',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dropout',\n",
       " 'dump_patches',\n",
       " 'embed_dim',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'head_dim',\n",
       " 'in_proj_bias',\n",
       " 'in_proj_weight',\n",
       " 'ipu',\n",
       " 'k_proj_weight',\n",
       " 'kdim',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_heads',\n",
       " 'out_proj',\n",
       " 'parameters',\n",
       " 'q_proj_weight',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'v_proj_weight',\n",
       " 'vdim',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.decoder.layers[-1].self_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d4f2fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder._modules[\"layers\"][-1].multihead_attn._parameters[\"in_proj_weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "607184d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('in_proj_weight',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.0294, -0.0511,  0.0045,  ...,  0.0381,  0.0291,  0.0405],\n",
       "                      [-0.0378, -0.0161,  0.0465,  ..., -0.0185, -0.0045,  0.0329],\n",
       "                      [-0.0140,  0.0475, -0.0318,  ...,  0.0461,  0.0257,  0.0066],\n",
       "                      ...,\n",
       "                      [-0.0535,  0.0461, -0.0355,  ..., -0.0245,  0.0480, -0.0154],\n",
       "                      [-0.0343, -0.0304,  0.0292,  ..., -0.0300,  0.0525,  0.0037],\n",
       "                      [ 0.0369, -0.0137, -0.0355,  ...,  0.0328,  0.0130, -0.0061]],\n",
       "                     requires_grad=True)),\n",
       "             ('q_proj_weight', None),\n",
       "             ('k_proj_weight', None),\n",
       "             ('v_proj_weight', None),\n",
       "             ('in_proj_bias',\n",
       "              Parameter containing:\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder._modules[\"layers\"][-1].multihead_attn._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34ae76be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_qkv_same_embed_dim',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_reset_parameters',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'add_zero_attn',\n",
       " 'apply',\n",
       " 'batch_first',\n",
       " 'bfloat16',\n",
       " 'bias_k',\n",
       " 'bias_v',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dropout',\n",
       " 'dump_patches',\n",
       " 'embed_dim',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'head_dim',\n",
       " 'in_proj_bias',\n",
       " 'in_proj_weight',\n",
       " 'ipu',\n",
       " 'k_proj_weight',\n",
       " 'kdim',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_heads',\n",
       " 'out_proj',\n",
       " 'parameters',\n",
       " 'q_proj_weight',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'v_proj_weight',\n",
       " 'vdim',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.decoder._modules[\"layers\"][-1].multihead_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0c070c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_ff_block',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_mha_block',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_sa_block',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'activation',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dropout',\n",
       " 'dropout1',\n",
       " 'dropout2',\n",
       " 'dropout3',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'linear1',\n",
       " 'linear2',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'multihead_attn',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'norm1',\n",
       " 'norm2',\n",
       " 'norm3',\n",
       " 'norm_first',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'self_attn',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.decoder._modules[\"layers\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28695ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_reset_parameters',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'batch_first',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'd_model',\n",
       " 'decoder',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'encoder',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'generate_square_subsequent_mask',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'nhead',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0d1c2",
   "metadata": {},
   "source": [
    "# data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35350994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 5359)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pickle.load(open(\"../../MSAI_Project/codes/data_files/data.json\", \"rb\"))\n",
    "type(data), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f602b930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pdb', 'Hchain', 'Lchain', 'Achain', 'Hseq', 'Lseq', 'Aseq', 'L1', 'L2', 'L3', 'H1', 'H2', 'H3', 'Hpos', 'Lpos', 'Apos'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b973ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0][\"Hpos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bbd607e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0][\"Lpos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7728cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0][\"Apos\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95eddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 81.858,  -7.199, 197.021],\n",
       "        [ 81.735,  -6.449, 198.265],\n",
       "        [ 80.284,  -6.421, 198.728],\n",
       "        [ 79.74 ,  -5.362, 199.036]], dtype=float32),\n",
       " array([[ 79.66 ,  -7.596, 198.767],\n",
       "        [ 78.278,  -7.837, 199.157],\n",
       "        [ 77.269,  -7.526, 198.055],\n",
       "        [ 76.075,  -7.745, 198.261]], dtype=float32),\n",
       " array([[ 77.695,  -7.022, 196.897],\n",
       "        [ 76.793,  -6.774, 195.785],\n",
       "        [ 77.323,  -7.296, 194.458],\n",
       "        [ 76.538,  -7.469, 193.52 ]], dtype=float32),\n",
       " array([[ 78.63 ,  -7.552, 194.352],\n",
       "        [ 79.196,  -8.074, 193.112],\n",
       "        [ 78.916,  -9.554, 192.915],\n",
       "        [ 78.921, -10.028, 191.772]], dtype=float32),\n",
       " array([[ 78.667, -10.296, 193.99 ],\n",
       "        [ 78.411, -11.718, 193.885],\n",
       "        [ 76.953, -12.063, 193.664],\n",
       "        [ 76.593, -13.242, 193.593]], dtype=float32),\n",
       " array([[ 76.106, -11.047, 193.552],\n",
       "        [ 74.68 , -11.249, 193.323],\n",
       "        [ 74.461, -11.614, 191.862],\n",
       "        [ 75.008, -10.971, 190.958]], dtype=float32),\n",
       " array([[ 73.675, -12.67 , 191.63 ],\n",
       "        [ 73.322, -13.068, 190.271],\n",
       "        [ 72.397, -12.067, 189.595],\n",
       "        [ 72.461, -11.907, 188.371]], dtype=float32),\n",
       " array([[ 71.545, -11.391, 190.36 ],\n",
       "        [ 70.701, -10.31 , 189.863],\n",
       "        [ 71.289,  -8.95 , 190.216],\n",
       "        [ 70.563,  -7.996, 190.506]], dtype=float32),\n",
       " array([[ 72.618,  -8.856, 190.212],\n",
       "        [ 73.313,  -7.63 , 190.578],\n",
       "        [ 73.185,  -6.595, 189.468],\n",
       "        [ 73.367,  -6.905, 188.287]], dtype=float32),\n",
       " array([[ 72.868,  -5.363, 189.856],\n",
       "        [ 72.686,  -4.265, 188.921],\n",
       "        [ 73.883,  -3.327, 188.991],\n",
       "        [ 74.338,  -2.955, 190.076]], dtype=float32),\n",
       " array([[ 74.391,  -2.953, 187.821],\n",
       "        [ 75.523,  -2.042, 187.705],\n",
       "        [ 74.979,  -0.645, 187.434],\n",
       "        [ 74.301,  -0.423, 186.425]], dtype=float32),\n",
       " array([[ 75.273,   0.289, 188.333],\n",
       "        [ 74.823,   1.671, 188.217],\n",
       "        [ 76.021,   2.511, 187.8  ],\n",
       "        [ 77.014,   2.6  , 188.532]], dtype=float32),\n",
       " array([[ 75.933,   3.119, 186.621],\n",
       "        [ 76.977,   4.006, 186.133],\n",
       "        [ 76.322,   5.242, 185.539],\n",
       "        [ 75.444,   5.149, 184.677]], dtype=float32),\n",
       " array([[ 76.757,   6.404, 186.014],\n",
       "        [ 76.191,   7.655, 185.555],\n",
       "        [ 74.98 ,   8.075, 186.361],\n",
       "        [ 74.008,   7.322, 186.47 ]], dtype=float32),\n",
       " array([[ 75.029,   9.274, 186.935],\n",
       "        [ 73.93 ,   9.824, 187.714],\n",
       "        [ 73.533,  11.17 , 187.122],\n",
       "        [ 74.112,  11.635, 186.137]], dtype=float32),\n",
       " array([[ 72.533,  11.804, 187.736],\n",
       "        [ 72.052,  13.114, 187.289],\n",
       "        [ 72.955,  14.212, 187.856],\n",
       "        [ 72.616,  14.933, 188.796]], dtype=float32),\n",
       " array([[ 74.142,  14.32 , 187.259],\n",
       "        [ 75.151,  15.252, 187.721],\n",
       "        [ 75.841,  14.866, 189.009],\n",
       "        [ 76.545,  15.694, 189.592]], dtype=float32),\n",
       " array([[ 75.661,  13.632, 189.476],\n",
       "        [ 76.196,  13.203, 190.75 ],\n",
       "        [ 75.354,  13.56 , 191.953],\n",
       "        [ 75.684,  13.138, 193.068]], dtype=float32),\n",
       " array([[ 74.271,  14.316, 191.765],\n",
       "        [ 73.444,  14.751, 192.884],\n",
       "        [ 72.382,  13.714, 193.227],\n",
       "        [ 72.331,  13.213, 194.353]], dtype=float32),\n",
       " array([[ 71.523,  13.381, 192.267],\n",
       "        [ 70.45 ,  12.432, 192.519],\n",
       "        [ 70.492,  11.337, 191.465],\n",
       "        [ 70.586,  11.606, 190.265]], dtype=float32),\n",
       " array([[ 70.425,  10.093, 191.934],\n",
       "        [ 70.319,   8.933, 191.058],\n",
       "        [ 69.059,   8.164, 191.432],\n",
       "        [ 68.815,   7.879, 192.607]], dtype=float32),\n",
       " array([[ 68.252,   7.836, 190.429],\n",
       "        [ 67.02 ,   7.085, 190.633],\n",
       "        [ 67.333,   5.601, 190.498],\n",
       "        [ 67.762,   5.151, 189.431]], dtype=float32),\n",
       " array([[ 67.117,   4.845, 191.574],\n",
       "        [ 67.424,   3.422, 191.589],\n",
       "        [ 66.201,   2.649, 192.062],\n",
       "        [ 65.301,   3.194, 192.707]], dtype=float32),\n",
       " array([[ 66.174,   1.364, 191.726],\n",
       "        [ 65.098,   0.459, 192.118],\n",
       "        [ 65.629,  -0.369, 193.281],\n",
       "        [ 66.433,  -1.288, 193.088]], dtype=float32),\n",
       " array([[ 6.51850e+01, -4.80000e-02,  1.94494e+02],\n",
       "        [ 6.56200e+01, -7.62000e-01,  1.95694e+02],\n",
       "        [ 6.48000e+01, -2.04100e+00,  1.95803e+02],\n",
       "        [ 6.37640e+01, -2.08400e+00,  1.96467e+02]], dtype=float32),\n",
       " array([[ 65.27 ,  -3.093, 195.138],\n",
       "        [ 64.566,  -4.365, 195.142],\n",
       "        [ 64.773,  -5.092, 196.469],\n",
       "        [ 65.832,  -5.011, 197.098]], dtype=float32),\n",
       " array([[ 63.728,  -5.803, 196.895],\n",
       "        [ 63.777,  -6.596, 198.117],\n",
       "        [ 64.678,  -7.815, 197.987],\n",
       "        [ 65.271,  -8.249, 198.981]], dtype=float32),\n",
       " array([[ 64.792,  -8.379, 196.788],\n",
       "        [ 65.664,  -9.515, 196.573],\n",
       "        [ 66.943,  -9.198, 195.829],\n",
       "        [ 67.862, -10.021, 195.801]], dtype=float32),\n",
       " array([[ 67.022,  -8.016, 195.223],\n",
       "        [ 68.179,  -7.632, 194.445],\n",
       "        [ 69.096,  -6.661, 195.167],\n",
       "        [ 68.748,  -6.068, 196.188]], dtype=float32),\n",
       " array([[ 70.295,  -6.507, 194.609],\n",
       "        [ 71.272,  -5.54 , 195.086],\n",
       "        [ 71.858,  -4.817, 193.883],\n",
       "        [ 72.127,  -5.426, 192.846]], dtype=float32),\n",
       " array([[ 72.054,  -3.51 , 194.028],\n",
       "        [ 72.504,  -2.661, 192.93 ],\n",
       "        [ 73.844,  -2.052, 193.312],\n",
       "        [ 73.965,  -1.428, 194.371]], dtype=float32),\n",
       " array([[ 74.845,  -2.234, 192.457],\n",
       "        [ 76.171,  -1.66 , 192.656],\n",
       "        [ 76.255,  -0.38 , 191.835],\n",
       "        [ 75.962,  -0.389, 190.635]], dtype=float32),\n",
       " array([[ 76.654,   0.712, 192.478],\n",
       "        [ 76.725,   2.026, 191.85 ],\n",
       "        [ 78.192,   2.406, 191.71 ],\n",
       "        [ 78.952,   2.359, 192.686]], dtype=float32),\n",
       " array([[ 78.591,   2.774, 190.495],\n",
       "        [ 79.935,   3.256, 190.216],\n",
       "        [ 79.84 ,   4.679, 189.685],\n",
       "        [ 79.082,   4.953, 188.75 ]], dtype=float32),\n",
       " array([[ 80.614,   5.58 , 190.285],\n",
       "        [ 80.558,   6.997, 189.952],\n",
       "        [ 81.928,   7.493, 189.494],\n",
       "        [ 82.909,   6.745, 189.481]], dtype=float32),\n",
       " array([[ 81.985,   8.771, 189.11 ],\n",
       "        [ 83.221,   9.351, 188.596],\n",
       "        [ 84.229,   9.611, 189.71 ],\n",
       "        [ 85.427,   9.363, 189.543]], dtype=float32),\n",
       " array([[ 83.763,  10.113, 190.853],\n",
       "        [ 84.638,  10.453, 191.968],\n",
       "        [ 84.232,   9.716, 193.236],\n",
       "        [ 84.616,  10.103, 194.344]], dtype=float32),\n",
       " array([[ 83.456,   8.649, 193.095],\n",
       "        [ 83.014,   7.862, 194.23 ],\n",
       "        [ 83.301,   6.393, 193.966],\n",
       "        [ 83.36 ,   5.964, 192.809]], dtype=float32),\n",
       " array([[ 83.489,   5.602, 195.02 ],\n",
       "        [ 83.712,   4.167, 194.823],\n",
       "        [ 82.406,   3.448, 194.531],\n",
       "        [ 81.317,   4.007, 194.681]], dtype=float32),\n",
       " array([[ 82.527,   2.194, 194.101],\n",
       "        [ 81.363,   1.366, 193.807],\n",
       "        [ 80.73 ,   0.935, 195.123],\n",
       "        [ 81.357,   0.235, 195.924]], dtype=float32),\n",
       " array([[7.94950e+01, 1.36000e+00, 1.95356e+02],\n",
       "        [7.87610e+01, 1.01600e+00, 1.96568e+02],\n",
       "        [7.75960e+01, 1.20000e-01, 1.96180e+02],\n",
       "        [7.67770e+01, 4.81000e-01, 1.95329e+02]], dtype=float32),\n",
       " array([[ 77.535,  -1.058, 196.785],\n",
       "        [ 76.449,  -2.001, 196.564],\n",
       "        [ 75.405,  -1.773, 197.647],\n",
       "        [ 75.71 ,  -1.883, 198.838]], dtype=float32),\n",
       " array([[ 74.189,  -1.434, 197.232],\n",
       "        [ 73.063,  -1.24 , 198.135],\n",
       "        [ 72.093,  -2.389, 197.911],\n",
       "        [ 71.667,  -2.637, 196.776]], dtype=float32),\n",
       " array([[ 71.757,  -3.094, 198.987],\n",
       "        [ 70.84 ,  -4.223, 198.91 ],\n",
       "        [ 69.791,  -4.065, 199.998],\n",
       "        [ 70.122,  -4.104, 201.186]], dtype=float32),\n",
       " array([[ 68.539,  -3.871, 199.593],\n",
       "        [ 67.436,  -3.795, 200.54 ],\n",
       "        [ 67.078,  -5.205, 200.989],\n",
       "        [ 66.191,  -5.842, 200.413]], dtype=float32),\n",
       " array([[ 67.768,  -5.691, 202.018],\n",
       "        [ 67.633,  -7.068, 202.466],\n",
       "        [ 66.61 ,  -7.205, 203.585],\n",
       "        [ 65.845,  -8.172, 203.615]], dtype=float32),\n",
       " array([[ 66.572,  -6.247, 204.506],\n",
       "        [ 65.653,  -6.3  , 205.629],\n",
       "        [ 64.344,  -5.64 , 205.226],\n",
       "        [ 64.318,  -4.684, 204.449]], dtype=float32),\n",
       " array([[ 63.245,  -6.182, 205.75 ],\n",
       "        [ 61.917,  -5.596, 205.557],\n",
       "        [ 61.093,  -5.963, 206.791],\n",
       "        [ 60.551,  -7.066, 206.88 ]], dtype=float32),\n",
       " array([[ 61.006,  -5.031, 207.735],\n",
       "        [ 60.323,  -5.277, 208.999],\n",
       "        [ 58.948,  -4.62 , 208.97 ],\n",
       "        [ 58.839,  -3.399, 208.813]], dtype=float32),\n",
       " array([[ 57.905,  -5.429, 209.126],\n",
       "        [ 56.538,  -4.933, 209.254],\n",
       "        [ 56.169,  -5.018, 210.731],\n",
       "        [ 56.084,  -6.111, 211.297]], dtype=float32),\n",
       " array([[ 55.947,  -3.866, 211.356],\n",
       "        [ 55.717,  -3.79 , 212.791],\n",
       "        [ 54.302,  -3.306, 213.081],\n",
       "        [ 53.793,  -2.399, 212.415]], dtype=float32),\n",
       " array([[ 53.69 ,  -3.899, 214.109],\n",
       "        [ 52.331,  -3.575, 214.545],\n",
       "        [ 51.292,  -3.937, 213.48 ],\n",
       "        [ 50.555,  -3.092, 212.97 ]], dtype=float32),\n",
       " array([[ 51.252,  -5.224, 213.151],\n",
       "        [ 50.266,  -5.744, 212.212],\n",
       "        [ 49.021,  -6.153, 212.989],\n",
       "        [ 49.009,  -7.191, 213.658]], dtype=float32),\n",
       " array([[ 47.974,  -5.337, 212.897],\n",
       "        [ 46.741,  -5.546, 213.643],\n",
       "        [ 45.919,  -6.638, 212.974],\n",
       "        [ 45.913,  -6.754, 211.746]], dtype=float32),\n",
       " array([[ 45.23 ,  -7.433, 213.791],\n",
       "        [ 44.503,  -8.604, 213.324],\n",
       "        [ 43.267,  -8.21 , 212.521],\n",
       "        [ 42.676,  -7.146, 212.715]], dtype=float32),\n",
       " array([[ 42.891,  -9.091, 211.597],\n",
       "        [ 41.747,  -8.882, 210.718],\n",
       "        [ 40.785, -10.043, 210.916],\n",
       "        [ 41.016, -10.903, 211.773]], dtype=float32),\n",
       " array([[ 39.692, -10.051, 210.15 ],\n",
       "        [ 38.72 , -11.136, 210.217],\n",
       "        [ 39.316, -12.424, 209.66 ],\n",
       "        [ 39.545, -12.555, 208.455]], dtype=float32),\n",
       " array([[ 39.573, -13.371, 210.558],\n",
       "        [ 40.3  , -14.599, 210.249],\n",
       "        [ 39.313, -15.758, 210.259],\n",
       "        [ 38.64 , -15.999, 211.268]], dtype=float32),\n",
       " array([[ 39.227, -16.464, 209.136],\n",
       "        [ 38.341, -17.609, 209.007],\n",
       "        [ 38.89 , -18.804, 209.78 ],\n",
       "        [ 40.093, -18.92 , 210.029]], dtype=float32),\n",
       " array([[ 37.981, -19.69 , 210.177],\n",
       "        [ 38.332, -20.923, 210.865],\n",
       "        [ 38.971, -21.892, 209.88 ],\n",
       "        [ 38.506, -22.038, 208.746]], dtype=float32),\n",
       " array([[ 40.041, -22.554, 210.32 ],\n",
       "        [ 40.784, -23.476, 209.476],\n",
       "        [ 40.424, -24.938, 209.681],\n",
       "        [ 40.634, -25.738, 208.764]], dtype=float32),\n",
       " array([[ 39.899, -25.311, 210.845],\n",
       "        [ 39.418, -26.665, 211.1  ],\n",
       "        [ 38.402, -26.587, 212.231],\n",
       "        [ 38.773, -26.368, 213.389]], dtype=float32),\n",
       " array([[ 37.128, -26.764, 211.897],\n",
       "        [ 36.054, -26.728, 212.873],\n",
       "        [ 35.675, -28.146, 213.289],\n",
       "        [ 36.289, -29.133, 212.877]], dtype=float32),\n",
       " array([[ 34.643, -28.242, 214.122],\n",
       "        [ 34.123, -29.536, 214.543],\n",
       "        [ 32.804, -29.314, 215.263],\n",
       "        [ 32.621, -28.299, 215.943]], dtype=float32),\n",
       " array([[ 31.897, -30.275, 215.13 ],\n",
       "        [ 30.558, -30.171, 215.696],\n",
       "        [ 30.61 , -30.647, 217.141],\n",
       "        [ 31.432, -31.5  , 217.494]], dtype=float32),\n",
       " array([[ 29.73 , -30.099, 217.971],\n",
       "        [ 29.603, -30.501, 219.364],\n",
       "        [ 28.567, -31.622, 219.466],\n",
       "        [ 28.289, -32.313, 218.482]], dtype=float32),\n",
       " array([[ 28.019, -31.84 , 220.662],\n",
       "        [ 26.946, -32.809, 220.851],\n",
       "        [ 25.669, -32.329, 220.173],\n",
       "        [ 25.016, -31.394, 220.647]], dtype=float32),\n",
       " array([[ 25.311, -32.962, 219.063],\n",
       "        [ 24.18 , -32.54 , 218.255],\n",
       "        [ 22.939, -33.351, 218.603],\n",
       "        [ 23.013, -34.514, 219.006]], dtype=float32),\n",
       " array([[ 21.785, -32.716, 218.433],\n",
       "        [ 20.504, -33.358, 218.682],\n",
       "        [ 19.515, -32.833, 217.654],\n",
       "        [ 19.833, -31.957, 216.846]], dtype=float32),\n",
       " array([[ 18.305, -33.383, 217.687],\n",
       "        [ 17.291, -32.992, 216.723],\n",
       "        [ 15.977, -32.759, 217.448],\n",
       "        [ 15.623, -33.478, 218.385]], dtype=float32),\n",
       " array([[ 15.262, -31.735, 216.995],\n",
       "        [ 13.907, -31.459, 217.442],\n",
       "        [ 12.984, -31.71 , 216.262],\n",
       "        [ 13.153, -31.114, 215.195]], dtype=float32),\n",
       " array([[ 12.023, -32.607, 216.457],\n",
       "        [ 11.14 , -33.039, 215.388],\n",
       "        [  9.696, -32.72 , 215.744],\n",
       "        [  9.238, -32.976, 216.861]], dtype=float32),\n",
       " array([[  8.988, -32.148, 214.778],\n",
       "        [  7.554, -31.935, 214.857],\n",
       "        [  6.901, -32.69 , 213.709],\n",
       "        [  7.528, -32.938, 212.675]], dtype=float32),\n",
       " array([[  5.634, -33.05 , 213.899],\n",
       "        [  4.917, -33.85 , 212.922],\n",
       "        [  4.488, -32.997, 211.73 ],\n",
       "        [  4.602, -31.768, 211.756]], dtype=float32),\n",
       " array([[  4.008, -33.637, 210.662],\n",
       "        [  3.514, -32.879, 209.503],\n",
       "        [  2.192, -32.201, 209.83 ],\n",
       "        [  1.159, -32.854, 209.985]], dtype=float32),\n",
       " array([[ 2.24100e+00, -3.08740e+01,  2.09942e+02],\n",
       "        [ 1.12600e+00, -3.00940e+01,  2.10471e+02],\n",
       "        [ 1.06700e+00, -3.01740e+01,  2.11993e+02],\n",
       "        [ 3.00000e-02, -2.99190e+01,  2.12609e+02]], dtype=float32),\n",
       " array([[  2.197, -30.532, 212.607],\n",
       "        [  2.312, -30.644, 214.056],\n",
       "        [  3.334, -29.665, 214.623],\n",
       "        [  3.912, -29.917, 215.684]], dtype=float32),\n",
       " array([[  3.57 , -28.555, 213.932],\n",
       "        [  4.504, -27.544, 214.38 ],\n",
       "        [  5.905, -27.787, 213.848],\n",
       "        [  6.318, -28.92 , 213.58 ]], dtype=float32),\n",
       " array([[  6.642, -26.691, 213.698],\n",
       "        [  8.014, -26.72 , 213.219],\n",
       "        [  8.954, -27.013, 214.379],\n",
       "        [  8.59 , -26.874, 215.55 ]], dtype=float32),\n",
       " array([[ 10.169, -27.433, 214.04 ],\n",
       "        [ 11.166, -27.756, 215.047],\n",
       "        [ 11.736, -26.48 , 215.656],\n",
       "        [ 12.172, -25.568, 214.949]], dtype=float32),\n",
       " array([[ 11.725, -26.425, 216.984],\n",
       "        [ 12.292, -25.293, 217.708],\n",
       "        [ 13.193, -25.856, 218.793],\n",
       "        [ 12.726, -26.135, 219.901]], dtype=float32),\n",
       " array([[ 14.471, -26.028, 218.47 ],\n",
       "        [ 15.44 , -26.61 , 219.384],\n",
       "        [ 15.806, -25.615, 220.477],\n",
       "        [ 15.88 , -24.406, 220.244]], dtype=float32),\n",
       " array([[ 16.012, -26.144, 221.688],\n",
       "        [ 16.51 , -25.333, 222.792],\n",
       "        [ 17.943, -24.877, 222.561],\n",
       "        [ 18.296, -23.757, 222.946]], dtype=float32),\n",
       " array([[ 18.769, -25.715, 221.936],\n",
       "        [ 20.098, -25.324, 221.487],\n",
       "        [ 20.061, -24.619, 220.138],\n",
       "        [ 21.081, -24.087, 219.689]], dtype=float32),\n",
       " array([[ 18.9  , -24.61 , 219.479],\n",
       "        [ 18.716, -23.86 , 218.244],\n",
       "        [ 18.71 , -22.355, 218.469],\n",
       "        [ 19.073, -21.602, 217.559]], dtype=float32),\n",
       " array([[ 18.307, -21.903, 219.654],\n",
       "        [ 18.381, -20.496, 220.015],\n",
       "        [ 19.715, -20.119, 220.646],\n",
       "        [ 19.921, -18.947, 220.976]], dtype=float32),\n",
       " array([[ 20.619, -21.079, 220.818],\n",
       "        [ 21.939, -20.82 , 221.375],\n",
       "        [ 22.889, -20.449, 220.245],\n",
       "        [ 22.941, -21.138, 219.222]], dtype=float32),\n",
       " array([[ 23.63 , -19.355, 220.431],\n",
       "        [ 24.561, -18.868, 219.421],\n",
       "        [ 25.786, -19.757, 219.254],\n",
       "        [ 26.377, -19.771, 218.169]], dtype=float32),\n",
       " array([[ 26.176, -20.496, 220.289],\n",
       "        [ 27.307, -21.409, 220.204],\n",
       "        [ 26.992, -22.676, 219.422],\n",
       "        [ 27.922, -23.356, 218.975]], dtype=float32),\n",
       " array([[ 25.717, -23.009, 219.244],\n",
       "        [ 25.307, -24.195, 218.508],\n",
       "        [ 24.735, -23.78 , 217.159],\n",
       "        [ 23.766, -23.017, 217.093]], dtype=float32),\n",
       " array([[ 25.34 , -24.282, 216.091],\n",
       "        [ 24.821, -24.094, 214.742],\n",
       "        [ 23.778, -25.17 , 214.48 ],\n",
       "        [ 23.949, -26.335, 214.861]], dtype=float32),\n",
       " array([[ 22.685, -24.778, 213.831],\n",
       "        [ 21.577, -25.69 , 213.592],\n",
       "        [ 21.083, -25.535, 212.162],\n",
       "        [ 21.235, -24.473, 211.553]], dtype=float32),\n",
       " array([[ 20.494, -26.607, 211.638],\n",
       "        [ 19.899, -26.617, 210.31 ],\n",
       "        [ 18.529, -27.271, 210.397],\n",
       "        [ 18.393, -28.37 , 210.943]], dtype=float32),\n",
       " array([[ 17.52 , -26.588, 209.869],\n",
       "        [ 16.158, -27.098, 209.835],\n",
       "        [ 15.847, -27.639, 208.446],\n",
       "        [ 16.37 , -27.15 , 207.441]], dtype=float32),\n",
       " array([[ 14.991, -28.656, 208.396],\n",
       "        [ 14.635, -29.295, 207.139],\n",
       "        [ 13.272, -29.955, 207.289],\n",
       "        [ 12.749, -30.114, 208.397]], dtype=float32),\n",
       " array([[ 12.694, -30.329, 206.151],\n",
       "        [ 11.406, -31.009, 206.096],\n",
       "        [ 11.658, -32.483, 205.811],\n",
       "        [ 12.051, -32.845, 204.698]], dtype=float32),\n",
       " array([[ 11.43 , -33.327, 206.814],\n",
       "        [ 11.665, -34.759, 206.701],\n",
       "        [ 10.322, -35.478, 206.685],\n",
       "        [  9.271, -34.885, 206.921]], dtype=float32),\n",
       " array([[ 10.368, -36.774, 206.394],\n",
       "        [  9.147, -37.563, 206.305],\n",
       "        [  8.692, -37.977, 207.699],\n",
       "        [  9.469, -38.548, 208.471]], dtype=float32),\n",
       " array([[  7.435, -37.683, 208.023],\n",
       "        [  6.816, -38.132, 209.263],\n",
       "        [  5.477, -38.763, 208.917],\n",
       "        [  4.615, -38.109, 208.322]], dtype=float32),\n",
       " array([[  5.301, -40.024, 209.29 ],\n",
       "        [  4.09 , -40.737, 208.949],\n",
       "        [  3.439, -41.399, 210.141],\n",
       "        [  3.864, -41.201, 211.282]], dtype=float32),\n",
       " array([[  2.381, -42.172, 209.868],\n",
       "        [  1.743, -42.992, 210.894],\n",
       "        [  2.681, -44.069, 211.421],\n",
       "        [  2.701, -44.331, 212.628]], dtype=float32),\n",
       " array([[  3.46 , -44.696, 210.538],\n",
       "        [  4.553, -45.535, 210.991],\n",
       "        [  5.778, -44.747, 211.404],\n",
       "        [  6.655, -45.285, 212.086]], dtype=float32),\n",
       " array([[  5.853, -43.474, 211.007],\n",
       "        [  6.966, -42.598, 211.345],\n",
       "        [  6.728, -41.809, 212.627],\n",
       "        [  7.52 , -40.917, 212.953]], dtype=float32),\n",
       " array([[  5.65 , -42.106, 213.353],\n",
       "        [  5.377, -41.48 , 214.626],\n",
       "        [  4.417, -40.312, 214.587],\n",
       "        [  3.855, -39.96 , 215.632]], dtype=float32),\n",
       " array([[  4.205, -39.7  , 213.426],\n",
       "        [  3.261, -38.598, 213.319],\n",
       "        [  1.84 , -39.146, 213.205],\n",
       "        [  1.618, -40.346, 213.018]], dtype=float32),\n",
       " array([[  0.858, -38.258, 213.317],\n",
       "        [ -0.526, -38.672, 213.227],\n",
       "        [ -1.066, -38.584, 211.817],\n",
       "        [ -2.201, -38.988, 211.548]], dtype=float32),\n",
       " array([[ -0.253, -38.057, 210.905],\n",
       "        [ -0.635, -37.945, 209.5  ],\n",
       "        [  0.607, -38.195, 208.663],\n",
       "        [  1.692, -37.719, 209.014]], dtype=float32),\n",
       " array([[  0.456, -38.949, 207.577],\n",
       "        [  1.555, -39.165, 206.648],\n",
       "        [  1.823, -37.885, 205.868],\n",
       "        [  0.945, -37.376, 205.165]], dtype=float32),\n",
       " array([[  3.034, -37.362, 206.   ],\n",
       "        [  3.369, -36.101, 205.369],\n",
       "        [  4.778, -35.668, 205.717],\n",
       "        [  5.634, -36.477, 206.075]], dtype=float32),\n",
       " array([[  4.999, -34.362, 205.594],\n",
       "        [  6.325, -33.786, 205.782],\n",
       "        [  6.402, -33.075, 207.129],\n",
       "        [  5.95 , -31.936, 207.271]], dtype=float32),\n",
       " array([[  6.986, -33.748, 208.118],\n",
       "        [  7.268, -33.121, 209.395],\n",
       "        [  8.513, -32.26 , 209.324],\n",
       "        [  9.222, -32.235, 208.315]], dtype=float32),\n",
       " array([[  8.798, -31.555, 210.416],\n",
       "        [  9.913, -30.614, 210.412],\n",
       "        [ 10.933, -31.022, 211.465],\n",
       "        [ 10.604, -31.148, 212.646]], dtype=float32),\n",
       " array([[ 12.18 , -31.211, 211.038],\n",
       "        [ 13.243, -31.624, 211.944],\n",
       "        [ 14.388, -30.625, 211.874],\n",
       "        [ 14.836, -30.26 , 210.785]], dtype=float32),\n",
       " array([[ 14.863, -30.187, 213.036],\n",
       "        [ 15.974, -29.246, 213.125],\n",
       "        [ 17.081, -29.905, 213.934],\n",
       "        [ 16.856, -30.328, 215.072]], dtype=float32),\n",
       " array([[ 18.276, -29.977, 213.355],\n",
       "        [ 19.421, -30.621, 213.989],\n",
       "        [ 20.43 , -29.546, 214.363],\n",
       "        [ 20.844, -28.756, 213.51 ]], dtype=float32),\n",
       " array([[ 20.828, -29.525, 215.631],\n",
       "        [ 21.755, -28.531, 216.151],\n",
       "        [ 22.973, -29.215, 216.758],\n",
       "        [ 22.911, -30.381, 217.157]], dtype=float32),\n",
       " array([[ 24.083, -28.481, 216.82 ],\n",
       "        [ 25.318, -29.005, 217.397],\n",
       "        [ 26.262, -27.84 , 217.643],\n",
       "        [ 26.249, -26.867, 216.887]], dtype=float32),\n",
       " array([[ 27.088, -27.948, 218.682],\n",
       "        [ 27.98 , -26.86 , 219.074],\n",
       "        [ 29.164, -26.798, 218.115],\n",
       "        [ 30.233, -27.344, 218.403]], dtype=float32),\n",
       " array([[ 28.978, -26.123, 216.982],\n",
       "        [ 30.011, -26.043, 215.956],\n",
       "        [ 31.084, -25.05 , 216.386],\n",
       "        [ 30.889, -23.834, 216.294]], dtype=float32),\n",
       " array([[ 32.214, -25.572, 216.861],\n",
       "        [ 33.304, -24.744, 217.37 ],\n",
       "        [ 34.501, -24.912, 216.444],\n",
       "        [ 34.794, -26.026, 215.999]], dtype=float32),\n",
       " array([[ 35.182, -23.808, 216.154],\n",
       "        [ 36.373, -23.829, 215.316],\n",
       "        [ 37.577, -24.203, 216.171],\n",
       "        [ 37.991, -23.432, 217.042]], dtype=float32),\n",
       " array([[ 38.135, -25.39 , 215.922],\n",
       "        [ 39.259, -25.889, 216.709],\n",
       "        [ 40.554, -25.138, 216.426],\n",
       "        [ 41.463, -25.135, 217.263]], dtype=float32),\n",
       " array([[ 40.664, -24.509, 215.26 ],\n",
       "        [ 41.793, -23.643, 214.954],\n",
       "        [ 41.434, -22.783, 213.754],\n",
       "        [ 40.699, -23.227, 212.868]], dtype=float32),\n",
       " array([[ 41.96 , -21.562, 213.724],\n",
       "        [ 41.668, -20.618, 212.658],\n",
       "        [ 42.929, -19.868, 212.261],\n",
       "        [ 43.706, -19.427, 213.112]], dtype=float32),\n",
       " array([[ 43.121, -19.725, 210.954],\n",
       "        [ 44.191, -18.907, 210.406],\n",
       "        [ 43.806, -17.438, 210.53 ],\n",
       "        [ 42.674, -17.046, 210.233]], dtype=float32),\n",
       " array([[ 44.761, -16.625, 210.974],\n",
       "        [ 44.486, -15.231, 211.304],\n",
       "        [ 45.315, -14.336, 210.399],\n",
       "        [ 46.53 , -14.515, 210.29 ]], dtype=float32),\n",
       " array([[ 44.66 , -13.372, 209.757],\n",
       "        [ 45.338, -12.469, 208.85 ],\n",
       "        [ 45.555, -11.099, 209.46 ],\n",
       "        [ 44.599, -10.361, 209.709]], dtype=float32),\n",
       " array([[ 46.816, -10.761, 209.703],\n",
       "        [ 47.182,  -9.451, 210.212],\n",
       "        [ 47.098,  -8.422, 209.091],\n",
       "        [ 47.448,  -8.698, 207.941]], dtype=float32),\n",
       " array([[ 46.62 ,  -7.232, 209.437],\n",
       "        [ 46.551,  -6.13 , 208.49 ],\n",
       "        [ 47.745,  -5.214, 208.719],\n",
       "        [ 48.016,  -4.801, 209.85 ]], dtype=float32),\n",
       " array([[ 48.456,  -4.901, 207.641],\n",
       "        [ 49.689,  -4.124, 207.708],\n",
       "        [ 49.359,  -2.69 , 207.317],\n",
       "        [ 48.937,  -2.424, 206.185]], dtype=float32),\n",
       " array([[ 4.95490e+01, -1.76700e+00,  2.08254e+02],\n",
       "        [ 4.93770e+01, -3.45000e-01,  2.07997e+02],\n",
       "        [ 5.05880e+01,  1.95000e-01,  2.07245e+02],\n",
       "        [ 5.16440e+01, -4.48000e-01,  2.07228e+02]], dtype=float32),\n",
       " array([[ 50.462,   1.363, 206.608],\n",
       "        [ 51.612,   1.936, 205.89 ],\n",
       "        [ 52.706,   2.479, 206.794],\n",
       "        [ 53.836,   2.657, 206.323]], dtype=float32),\n",
       " array([[ 52.419,   2.738, 208.067],\n",
       "        [ 53.41 ,   3.252, 209.   ],\n",
       "        [ 54.106,   2.157, 209.797],\n",
       "        [ 54.655,   2.439, 210.867]], dtype=float32),\n",
       " array([[ 5.40960e+01,  9.17000e-01,  2.09307e+02],\n",
       "        [ 5.47400e+01, -1.89000e-01,  2.10001e+02],\n",
       "        [ 5.59200e+01, -7.64000e-01,  2.09229e+02],\n",
       "        [ 5.66810e+01, -1.56200e+00,  2.09789e+02]], dtype=float32),\n",
       " array([[ 56.095,  -0.383, 207.968],\n",
       "        [ 57.172,  -0.932, 207.158],\n",
       "        [ 58.488,  -0.231, 207.472],\n",
       "        [ 58.521,   0.966, 207.769]], dtype=float32),\n",
       " array([[ 59.58 ,  -0.993, 207.405],\n",
       "        [ 60.934,  -0.481, 207.628],\n",
       "        [ 61.877,  -1.346, 206.796],\n",
       "        [ 62.118,  -2.51 , 207.126]], dtype=float32),\n",
       " array([[ 6.24050e+01, -7.75000e-01,  2.05715e+02],\n",
       "        [ 6.32890e+01, -1.51100e+00,  2.04823e+02],\n",
       "        [ 6.47340e+01, -1.32500e+00,  2.05270e+02],\n",
       "        [ 6.52250e+01, -1.95000e-01,  2.05351e+02]], dtype=float32),\n",
       " array([[ 65.412,  -2.43 , 205.568],\n",
       "        [ 66.814,  -2.395, 205.964],\n",
       "        [ 67.679,  -2.627, 204.731],\n",
       "        [ 67.69 ,  -3.73 , 204.171]], dtype=float32),\n",
       " array([[ 68.407,  -1.595, 204.316],\n",
       "        [ 69.238,  -1.649, 203.121],\n",
       "        [ 70.686,  -1.564, 203.582],\n",
       "        [ 71.077,  -0.62 , 204.277]], dtype=float32),\n",
       " array([[ 71.479,  -2.56 , 203.21 ],\n",
       "        [ 72.899,  -2.558, 203.518],\n",
       "        [ 73.669,  -1.979, 202.34 ],\n",
       "        [ 73.527,  -2.441, 201.204]], dtype=float32),\n",
       " array([[ 74.466,  -0.95 , 202.613],\n",
       "        [ 75.377,  -0.38 , 201.637],\n",
       "        [ 76.777,  -0.888, 201.944],\n",
       "        [ 77.124,  -1.135, 203.101]], dtype=float32),\n",
       " array([[ 77.57 ,  -1.077, 200.895],\n",
       "        [ 78.921,  -1.604, 201.069],\n",
       "        [ 79.799,  -1.011, 199.979],\n",
       "        [ 79.563,  -1.261, 198.795]], dtype=float32),\n",
       " array([[ 80.798,  -0.232, 200.374],\n",
       "        [ 81.716,   0.351, 199.406],\n",
       "        [ 82.724,  -0.701, 198.959],\n",
       "        [ 83.474,  -1.265, 199.761]], dtype=float32),\n",
       " array([[ 8.27300e+01, -9.73000e-01,  1.97656e+02],\n",
       "        [ 8.36900e+01, -1.89500e+00,  1.97064e+02],\n",
       "        [ 8.50450e+01, -1.20400e+00,  1.97013e+02],\n",
       "        [ 8.51660e+01, -1.01000e-01,  1.96469e+02]], dtype=float32),\n",
       " array([[ 86.06 ,  -1.852, 197.575],\n",
       "        [ 87.344,  -1.21 , 197.766],\n",
       "        [ 88.281,  -2.025, 198.63 ],\n",
       "        [ 88.501,  -3.212, 198.369]], dtype=float32),\n",
       " array([[ 88.846,  -1.395, 199.661],\n",
       "        [ 89.825,  -2.046, 200.53 ],\n",
       "        [ 89.125,  -3.032, 201.464],\n",
       "        [ 88.792,  -2.73 , 202.613]], dtype=float32),\n",
       " array([[ 88.905,  -4.237, 200.942],\n",
       "        [ 88.345,  -5.343, 201.701],\n",
       "        [ 88.84 ,  -6.641, 201.083],\n",
       "        [ 89.199,  -6.687, 199.905]], dtype=float32),\n",
       " array([[ 88.855,  -7.696, 201.886],\n",
       "        [ 89.344,  -8.996, 201.453],\n",
       "        [ 88.176,  -9.848, 200.959],\n",
       "        [ 87.044,  -9.375, 200.825]], dtype=float32),\n",
       " array([[ 88.467, -11.122, 200.683],\n",
       "        [ 87.425, -12.059, 200.279],\n",
       "        [ 86.517, -12.445, 201.439],\n",
       "        [ 85.372, -12.85 , 201.21 ]], dtype=float32),\n",
       " array([[ 86.996, -12.319, 202.676],\n",
       "        [ 86.204, -12.638, 203.847],\n",
       "        [ 85.328, -11.5  , 204.329],\n",
       "        [ 84.663, -11.618, 205.362]], dtype=float32),\n",
       " array([[ 85.327, -10.383, 203.596],\n",
       "        [ 84.431,  -9.273, 203.89 ],\n",
       "        [ 83.347,  -9.123, 202.83 ],\n",
       "        [ 82.463,  -8.27 , 202.975]], dtype=float32),\n",
       " array([[ 83.401,  -9.92 , 201.762],\n",
       "        [ 82.35 ,  -9.922, 200.748],\n",
       "        [ 81.083, -10.556, 201.306],\n",
       "        [ 79.975, -10.046, 201.108]], dtype=float32),\n",
       " array([[ 81.239, -11.673, 202.018],\n",
       "        [ 80.098, -12.311, 202.666],\n",
       "        [ 80.123, -12.123, 204.176],\n",
       "        [ 79.096, -12.326, 204.837]], dtype=float32),\n",
       " array([[ 81.265, -11.739, 204.741],\n",
       "        [ 81.379, -11.54 , 206.182],\n",
       "        [ 80.726, -10.217, 206.559],\n",
       "        [ 81.382,  -9.172, 206.587]], dtype=float32),\n",
       " array([[ 79.427, -10.263, 206.849],\n",
       "        [ 78.672,  -9.077, 207.225],\n",
       "        [ 78.562,  -8.9  , 208.732],\n",
       "        [ 77.737,  -8.1  , 209.189]], dtype=float32),\n",
       " array([[ 79.359,  -9.63 , 209.514],\n",
       "        [ 79.334,  -9.511, 210.966],\n",
       "        [ 79.973,  -8.2  , 211.405],\n",
       "        [ 81.202,  -8.088, 211.466]], dtype=float32),\n",
       " array([[ 79.141,  -7.205, 211.702],\n",
       "        [ 79.616,  -5.897, 212.103],\n",
       "        [ 79.485,  -4.87 , 210.999],\n",
       "        [ 80.298,  -4.839, 210.071]], dtype=float32),\n",
       " array([[ 78.459,  -4.024, 211.086],\n",
       "        [ 78.26 ,  -2.962, 210.114],\n",
       "        [ 78.471,  -1.567, 210.68 ],\n",
       "        [ 78.825,  -0.66 , 209.919]], dtype=float32),\n",
       " array([[ 7.82620e+01, -1.36200e+00,  2.11982e+02],\n",
       "        [ 7.85290e+01, -6.40000e-02,  2.12584e+02],\n",
       "        [ 8.00170e+01,  2.08000e-01,  2.12744e+02],\n",
       "        [ 8.04450e+01,  1.35600e+00,  2.12593e+02]], dtype=float32),\n",
       " array([[ 80.815,  -0.819, 213.034],\n",
       "        [ 82.249,  -0.666, 213.238],\n",
       "        [ 83.05 ,  -1.075, 212.009],\n",
       "        [ 84.269,  -1.249, 212.087]], dtype=float32),\n",
       " array([[ 82.385,  -1.235, 210.864],\n",
       "        [ 83.064,  -1.668, 209.652],\n",
       "        [ 83.803,  -0.544, 208.942],\n",
       "        [ 85.023,  -0.631, 208.772]], dtype=float32),\n",
       " array([[ 83.098,   0.508, 208.523],\n",
       "        [ 83.697,   1.62 , 207.789],\n",
       "        [ 83.852,   1.348, 206.295],\n",
       "        [ 84.286,   2.227, 205.544]], dtype=float32),\n",
       " array([[ 8.35000e+01,  1.42000e-01,  2.05852e+02],\n",
       "        [ 8.33860e+01, -1.74000e-01,  2.04437e+02],\n",
       "        [ 8.19840e+01, -6.05000e-01,  2.04046e+02],\n",
       "        [ 8.15800e+01, -3.88000e-01,  2.02900e+02]], dtype=float32),\n",
       " array([[ 81.242,  -1.207, 204.972],\n",
       "        [ 79.847,  -1.562, 204.776],\n",
       "        [ 79.077,  -1.249, 206.051],\n",
       "        [ 79.634,  -1.274, 207.152]], dtype=float32),\n",
       " array([[ 77.789,  -0.955, 205.889],\n",
       "        [ 76.917,  -0.638, 207.01 ],\n",
       "        [ 75.473,  -0.69 , 206.531],\n",
       "        [ 75.187,  -0.406, 205.366]], dtype=float32),\n",
       " array([[ 7.45740e+01, -1.06000e+00,  2.07435e+02],\n",
       "        [ 7.31550e+01, -1.14300e+00,  2.07126e+02],\n",
       "        [ 7.24310e+01,  8.90000e-02,  2.07655e+02],\n",
       "        [ 7.27350e+01,  5.92000e-01,  2.08739e+02]], dtype=float32),\n",
       " array([[ 71.472,   0.575, 206.872],\n",
       "        [ 70.648,   1.72 , 207.242],\n",
       "        [ 69.194,   1.298, 207.075],\n",
       "        [ 68.825,   0.69 , 206.063]], dtype=float32),\n",
       " array([[ 68.37 ,   1.605, 208.07 ],\n",
       "        [ 66.947,   1.299, 208.015],\n",
       "        [ 66.194,   2.551, 207.585],\n",
       "        [ 66.289,   3.596, 208.236]], dtype=float32),\n",
       " array([[ 65.451,   2.445, 206.491],\n",
       "        [ 64.649,   3.546, 205.967],\n",
       "        [ 63.192,   3.172, 206.211],\n",
       "        [ 62.733,   2.097, 205.814]], dtype=float32),\n",
       " array([[ 62.464,   4.054, 206.874],\n",
       "        [ 61.056,   3.826, 207.144],\n",
       "        [ 60.21 ,   4.851, 206.398],\n",
       "        [ 60.745,   5.727, 205.712]], dtype=float32),\n",
       " array([[ 58.88 ,   4.73 , 206.48 ],\n",
       "        [ 58.013,   5.808, 205.979],\n",
       "        [ 58.146,   7.106, 206.757],\n",
       "        [ 57.984,   8.183, 206.169]], dtype=float32),\n",
       " array([[ 58.44 ,   7.035, 208.057],\n",
       "        [ 58.657,   8.247, 208.837],\n",
       "        [ 60.016,   8.869, 208.545],\n",
       "        [ 60.183,  10.086, 208.677]], dtype=float32),\n",
       " array([[ 60.992,   8.059, 208.143],\n",
       "        [ 62.35 ,   8.527, 207.865],\n",
       "        [ 62.744,   8.081, 206.465],\n",
       "        [ 63.516,   7.131, 206.291]], dtype=float32),\n",
       " array([[ 62.215,   8.744, 205.434],\n",
       "        [ 62.591,   8.365, 204.064],\n",
       "        [ 63.954,   8.881, 203.644],\n",
       "        [ 64.644,   8.218, 202.86 ]], dtype=float32),\n",
       " array([[ 64.365,  10.043, 204.141],\n",
       "        [ 65.657,  10.616, 203.795],\n",
       "        [ 66.661,  10.308, 204.896],\n",
       "        [ 66.354,  10.439, 206.085]], dtype=float32),\n",
       " array([[ 67.86 ,   9.894, 204.496],\n",
       "        [ 68.916,   9.552, 205.435],\n",
       "        [ 70.266,   9.745, 204.759],\n",
       "        [ 70.36 ,   9.882, 203.538]], dtype=float32),\n",
       " array([[ 71.319,   9.756, 205.572],\n",
       "        [ 72.684,   9.896, 205.079],\n",
       "        [ 73.579,   8.981, 205.901],\n",
       "        [ 73.811,   9.237, 207.086]], dtype=float32),\n",
       " array([[ 74.079,   7.922, 205.273],\n",
       "        [ 74.947,   6.965, 205.943],\n",
       "        [ 76.396,   7.378, 205.724],\n",
       "        [ 76.881,   7.388, 204.589]], dtype=float32),\n",
       " array([[ 77.079,   7.718, 206.811],\n",
       "        [ 78.466,   8.167, 206.739],\n",
       "        [ 79.363,   6.946, 206.582],\n",
       "        [ 79.646,   6.238, 207.551]], dtype=float32),\n",
       " array([[ 79.808,   6.694, 205.356],\n",
       "        [ 80.718,   5.593, 205.055],\n",
       "        [ 82.125,   6.159, 205.191],\n",
       "        [ 82.548,   6.984, 204.378]], dtype=float32),\n",
       " array([[ 82.837,   5.716, 206.233],\n",
       "        [ 84.129,   6.257, 206.624],\n",
       "        [ 85.237,   6.142, 205.596],\n",
       "        [ 85.559,   5.047, 205.127]], dtype=float32),\n",
       " array([[ 85.817,   7.281, 205.239],\n",
       "        [ 86.746,   7.391, 204.128],\n",
       "        [ 86.074,   7.794, 202.831],\n",
       "        [ 86.566,   8.675, 202.123]], dtype=float32),\n",
       " array([[ 84.943,   7.17 , 202.512],\n",
       "        [ 84.209,   7.465, 201.29 ],\n",
       "        [ 83.278,   8.664, 201.417],\n",
       "        [ 82.727,   9.108, 200.405]], dtype=float32),\n",
       " array([[ 83.09 ,   9.198, 202.614],\n",
       "        [ 82.215,  10.342, 202.81 ],\n",
       "        [ 80.863,   9.927, 203.372],\n",
       "        [ 80.788,   9.301, 204.428]], dtype=float32),\n",
       " array([[ 79.794,  10.277, 202.659],\n",
       "        [ 78.446,   9.998, 203.149],\n",
       "        [ 77.552,   9.694, 201.956],\n",
       "        [ 77.381,  10.545, 201.079]], dtype=float32),\n",
       " array([[ 76.985,   8.492, 201.931],\n",
       "        [ 76.033,   8.125, 200.891],\n",
       "        [ 74.642,   8.584, 201.308],\n",
       "        [ 74.172,   8.254, 202.401]], dtype=float32),\n",
       " array([[ 73.98 ,   9.346, 200.44 ],\n",
       "        [ 72.669,   9.883, 200.744],\n",
       "        [ 71.563,   9.012, 200.179],\n",
       "        [ 71.471,   8.815, 198.966]], dtype=float32),\n",
       " array([[ 70.728,   8.487, 201.069],\n",
       "        [ 69.576,   7.695, 200.676],\n",
       "        [ 68.33 ,   8.57 , 200.679],\n",
       "        [ 68.02 ,   9.237, 201.67 ]], dtype=float32),\n",
       " array([[ 67.619,   8.559, 199.557],\n",
       "        [ 66.387,   9.321, 199.387],\n",
       "        [ 65.266,   8.385, 198.956],\n",
       "        [ 64.53 ,   8.647, 198.003]], dtype=float32),\n",
       " array([[ 65.158,   7.255, 199.652],\n",
       "        [ 64.139,   6.259, 199.362],\n",
       "        [ 62.759,   6.76 , 199.784],\n",
       "        [ 62.599,   7.467, 200.784]], dtype=float32),\n",
       " array([[ 61.751,   6.383, 198.997],\n",
       "        [ 60.365,   6.781, 199.235],\n",
       "        [ 59.666,   5.643, 199.964],\n",
       "        [ 59.194,   4.684, 199.332]], dtype=float32),\n",
       " array([[ 59.593,   5.702, 201.299],\n",
       "        [ 58.88 ,   4.655, 202.042],\n",
       "        [ 57.371,   4.727, 201.902],\n",
       "        [ 56.693,   3.715, 202.125]], dtype=float32),\n",
       " array([[ 56.828,   5.894, 201.552],\n",
       "        [ 55.41 ,   5.998, 201.24 ],\n",
       "        [ 55.069,   5.322, 199.92 ],\n",
       "        [ 53.972,   4.771, 199.777]], dtype=float32),\n",
       " array([[ 55.984,   5.349, 198.956],\n",
       "        [ 55.799,   4.638, 197.692],\n",
       "        [ 56.342,   3.214, 197.801],\n",
       "        [ 57.398,   2.872, 197.271]], dtype=float32),\n",
       " array([[5.55940e+01, 2.37900e+00, 1.98516e+02],\n",
       "        [5.60030e+01, 1.00600e+00, 1.98736e+02],\n",
       "        [5.54790e+01, 5.60000e-02, 1.97680e+02],\n",
       "        [5.49100e+01, 4.91000e-01, 1.96674e+02]], dtype=float32),\n",
       " array([[ 55.663,  -1.244, 197.894],\n",
       "        [ 55.247,  -2.255, 196.923],\n",
       "        [ 53.868,  -2.814, 197.274],\n",
       "        [ 53.675,  -4.021, 197.426]], dtype=float32),\n",
       " array([[ 52.895,  -1.903, 197.372],\n",
       "        [ 51.497,  -2.253, 197.609],\n",
       "        [ 51.25 ,  -2.839, 198.995],\n",
       "        [ 50.623,  -3.895, 199.123]], dtype=float32),\n",
       " array([[ 51.744,  -2.168, 200.037],\n",
       "        [ 51.578,  -2.654, 201.402],\n",
       "        [ 50.157,  -2.506, 201.928],\n",
       "        [ 49.785,  -3.23 , 202.859]], dtype=float32),\n",
       " array([[ 49.358,  -1.602, 201.366],\n",
       "        [ 47.987,  -1.412, 201.818],\n",
       "        [ 46.994,  -2.32 , 201.108],\n",
       "        [ 45.828,  -2.372, 201.51 ]], dtype=float32),\n",
       " array([[ 47.421,  -3.035, 200.068],\n",
       "        [ 46.533,  -3.911, 199.313],\n",
       "        [ 46.713,  -5.379, 199.685],\n",
       "        [ 46.138,  -6.259, 199.039]], dtype=float32),\n",
       " array([[ 47.496,  -5.661, 200.722],\n",
       "        [ 47.81 ,  -7.033, 201.085],\n",
       "        [ 47.717,  -7.216, 202.592],\n",
       "        [ 47.896,  -6.27 , 203.363]], dtype=float32),\n",
       " array([[ 47.436,  -8.448, 202.999],\n",
       "        [ 47.407,  -8.849, 204.398],\n",
       "        [ 48.425,  -9.969, 204.62 ],\n",
       "        [ 48.802, -10.688, 203.691]], dtype=float32),\n",
       " array([[ 48.88 , -10.107, 205.866],\n",
       "        [ 49.853, -11.134, 206.244],\n",
       "        [ 49.089, -12.222, 206.997],\n",
       "        [ 48.857, -12.112, 208.202]], dtype=float32),\n",
       " array([[ 48.674, -13.257, 206.273],\n",
       "        [ 47.965, -14.364, 206.895],\n",
       "        [ 48.949, -15.32 , 207.561],\n",
       "        [ 50.007, -15.645, 207.018]], dtype=float32),\n",
       " array([[ 48.586, -15.774, 208.759],\n",
       "        [ 49.393, -16.736, 209.503],\n",
       "        [ 48.516, -17.953, 209.765],\n",
       "        [ 47.39 , -17.815, 210.26 ]], dtype=float32),\n",
       " array([[ 49.033, -19.134, 209.425],\n",
       "        [ 48.333, -20.401, 209.63 ],\n",
       "        [ 49.392, -21.482, 209.825],\n",
       "        [ 50.091, -21.853, 208.878]], dtype=float32),\n",
       " array([[ 49.505, -21.983, 211.056],\n",
       "        [ 50.477, -23.02 , 211.399],\n",
       "        [ 51.901, -22.47 , 211.426],\n",
       "        [ 52.876, -23.192, 211.204]], dtype=float32),\n",
       " array([[ 52.016, -21.173, 211.708],\n",
       "        [ 53.298, -20.475, 211.669],\n",
       "        [ 53.766, -20.261, 210.233],\n",
       "        [ 54.961, -20.168, 209.949]], dtype=float32),\n",
       " array([[ 52.805, -20.188, 209.316],\n",
       "        [ 53.088, -19.992, 207.903],\n",
       "        [ 52.639, -18.596, 207.507],\n",
       "        [ 51.461, -18.378, 207.209]], dtype=float32),\n",
       " array([[ 53.578, -17.655, 207.515],\n",
       "        [ 53.307, -16.284, 207.118],\n",
       "        [ 53.22 , -16.21 , 205.601],\n",
       "        [ 54.1  , -16.697, 204.889]], dtype=float32),\n",
       " array([[ 52.146, -15.601, 205.111],\n",
       "        [ 51.949, -15.427, 203.681],\n",
       "        [ 51.353, -14.052, 203.428],\n",
       "        [ 50.336, -13.675, 204.013]], dtype=float32),\n",
       " array([[ 51.998, -13.298, 202.54 ],\n",
       "        [ 51.528, -11.967, 202.158],\n",
       "        [ 50.482, -12.126, 201.057],\n",
       "        [ 50.745, -11.927, 199.87 ]], dtype=float32),\n",
       " array([[ 49.273, -12.494, 201.474],\n",
       "        [ 48.173, -12.706, 200.542],\n",
       "        [ 47.567, -11.357, 200.187],\n",
       "        [ 47.823, -10.354, 200.863]], dtype=float32),\n",
       " array([[ 46.769, -11.329, 199.122],\n",
       "        [ 46.119, -10.097, 198.699],\n",
       "        [ 44.978,  -9.741, 199.647],\n",
       "        [ 44.493, -10.576, 200.418]], dtype=float32),\n",
       " array([[ 44.565,  -8.472, 199.593],\n",
       "        [ 43.478,  -8.001, 200.447],\n",
       "        [ 42.135,  -8.567, 200.001],\n",
       "        [ 41.276,  -8.872, 200.836]], dtype=float32),\n",
       " array([[ 41.942,  -8.719, 198.687],\n",
       "        [ 40.706,  -9.305, 198.176],\n",
       "        [ 40.636, -10.8  , 198.461],\n",
       "        [ 39.557, -11.325, 198.758]], dtype=float32),\n",
       " array([[ 41.772, -11.496, 198.376],\n",
       "        [ 41.807, -12.911, 198.724],\n",
       "        [ 41.699, -13.125, 200.227],\n",
       "        [ 41.14 , -14.136, 200.668]], dtype=float32),\n",
       " array([[ 42.236, -12.198, 201.024],\n",
       "        [ 42.094, -12.288, 202.472],\n",
       "        [ 40.674, -11.971, 202.92 ],\n",
       "        [ 40.195, -12.544, 203.905]], dtype=float32),\n",
       " array([[ 39.989, -11.075, 202.211],\n",
       "        [ 38.6  , -10.753, 202.496],\n",
       "        [ 37.625, -11.672, 201.771],\n",
       "        [ 36.409, -11.506, 201.912]], dtype=float32),\n",
       " array([[ 38.132, -12.632, 200.998],\n",
       "        [ 37.292, -13.581, 200.281],\n",
       "        [ 37.455, -15.013, 200.773],\n",
       "        [ 37.016, -15.943, 200.086]], dtype=float32),\n",
       " array([[ 38.072, -15.218, 201.932],\n",
       "        [ 38.293, -16.566, 202.458],\n",
       "        [ 36.998, -17.08 , 203.078],\n",
       "        [ 36.467, -16.454, 204.009]], dtype=float32),\n",
       " array([[ 36.457, -18.204, 202.605],\n",
       "        [ 35.195, -18.733, 203.168],\n",
       "        [ 35.406, -19.723, 204.311],\n",
       "        [ 35.23 , -20.937, 204.186]], dtype=float32),\n",
       " array([[ 35.799, -19.195, 205.462],\n",
       "        [ 35.992, -19.977, 206.672],\n",
       "        [ 35.093, -19.4  , 207.753],\n",
       "        [ 34.41 , -18.396, 207.524]], dtype=float32),\n",
       " array([[ 35.054, -20.024, 208.932],\n",
       "        [ 34.296, -19.438, 210.05 ],\n",
       "        [ 35.049, -18.242, 210.615],\n",
       "        [ 36.035, -18.397, 211.339]], dtype=float32),\n",
       " array([[ 34.562, -17.046, 210.295],\n",
       "        [ 35.308, -15.816, 210.502],\n",
       "        [ 35.098, -15.278, 211.909],\n",
       "        [ 34.045, -14.72 , 212.228]], dtype=float32),\n",
       " array([[ 36.116, -15.453, 212.746],\n",
       "        [ 36.233, -14.682, 213.973],\n",
       "        [ 36.506, -13.236, 213.582],\n",
       "        [ 37.307, -12.961, 212.685]], dtype=float32),\n",
       " array([[ 35.827, -12.307, 214.255],\n",
       "        [ 35.781, -10.923, 213.8  ],\n",
       "        [ 37.068, -10.158, 214.092],\n",
       "        [ 37.776,  -9.748, 213.167]], dtype=float32),\n",
       " array([[ 37.381,  -9.961, 215.371],\n",
       "        [ 38.529,  -9.162, 215.746],\n",
       "        [ 39.403,  -9.784, 216.813],\n",
       "        [ 39.875, -10.912, 216.639]], dtype=float32),\n",
       " array([[ 39.628,  -9.072, 217.915],\n",
       "        [ 40.45 ,  -9.565, 219.015],\n",
       "        [ 39.622, -10.264, 220.089],\n",
       "        [ 40.099, -10.467, 221.211]], dtype=float32),\n",
       " array([[ 38.384, -10.629, 219.763],\n",
       "        [ 37.519, -11.372, 220.674],\n",
       "        [ 38.014, -12.812, 220.687],\n",
       "        [ 37.588, -13.631, 219.867]], dtype=float32),\n",
       " array([[ 38.918, -13.117, 221.617],\n",
       "        [ 39.574, -14.416, 221.675],\n",
       "        [ 38.779, -15.454, 222.457],\n",
       "        [ 39.222, -16.598, 222.583]], dtype=float32),\n",
       " array([[ 37.606, -15.09 , 222.96 ],\n",
       "        [ 36.79 , -16.013, 223.724],\n",
       "        [ 35.925, -16.845, 222.804],\n",
       "        [ 36.426, -17.602, 221.967]], dtype=float32),\n",
       " array([[ 34.613, -16.726, 222.973],\n",
       "        [ 33.671, -17.373, 222.071],\n",
       "        [ 33.707, -16.64 , 220.736],\n",
       "        [ 33.298, -15.472, 220.673]], dtype=float32),\n",
       " array([[ 34.213, -17.258, 219.67 ],\n",
       "        [ 34.283, -16.575, 218.372],\n",
       "        [ 32.91 , -16.416, 217.741],\n",
       "        [ 31.99 , -17.2  , 217.993]], dtype=float32),\n",
       " array([[ 32.777, -15.364, 216.93 ],\n",
       "        [ 31.526, -15.091, 216.233],\n",
       "        [ 31.225, -16.133, 215.167],\n",
       "        [ 30.066, -16.54 , 215.021]], dtype=float32),\n",
       " array([[ 32.262, -16.62 , 214.481],\n",
       "        [ 32.145, -17.584, 213.389],\n",
       "        [ 31.315, -17.027, 212.23 ],\n",
       "        [ 30.239, -17.536, 211.903]], dtype=float32),\n",
       " array([[ 31.826, -15.945, 211.644],\n",
       "        [ 31.2  , -15.356, 210.469],\n",
       "        [ 31.359, -16.29 , 209.277],\n",
       "        [ 32.472, -16.597, 208.843]], dtype=float32),\n",
       " array([[ 30.224, -16.746, 208.749],\n",
       "        [ 30.192, -17.837, 207.779],\n",
       "        [ 30.635, -19.149, 208.428],\n",
       "        [ 31.398, -19.935, 207.863]], dtype=float32),\n",
       " array([[ 30.136, -19.372, 209.647],\n",
       "        [ 30.501, -20.571, 210.393],\n",
       "        [ 29.708, -21.788, 209.94 ],\n",
       "        [ 30.088, -22.923, 210.249]], dtype=float32),\n",
       " array([[ 28.617, -21.582, 209.205],\n",
       "        [ 27.791, -22.684, 208.732],\n",
       "        [ 28.367, -23.37 , 207.499],\n",
       "        [ 27.885, -24.441, 207.117]], dtype=float32),\n",
       " array([[ 29.383, -22.781, 206.873],\n",
       "        [ 30.003, -23.35 , 205.685],\n",
       "        [ 30.934, -24.517, 205.986],\n",
       "        [ 31.302, -25.249, 205.061]], dtype=float32),\n",
       " array([[ 31.323, -24.714, 207.245],\n",
       "        [ 32.235, -25.79 , 207.605],\n",
       "        [ 31.542, -27.121, 207.851],\n",
       "        [ 32.16 , -28.169, 207.646]], dtype=float32),\n",
       " array([[ 30.286, -27.111, 208.282],\n",
       "        [ 29.544, -28.342, 208.514],\n",
       "        [ 28.458, -28.488, 207.456],\n",
       "        [ 28.05 , -27.523, 206.804]], dtype=float32),\n",
       " array([[ 27.987, -29.721, 207.282],\n",
       "        [ 26.9  , -30.029, 206.361],\n",
       "        [ 25.952, -30.98 , 207.075],\n",
       "        [ 26.364, -32.062, 207.504]], dtype=float32),\n",
       " array([[ 24.698, -30.566, 207.229],\n",
       "        [ 23.673, -31.392, 207.859],\n",
       "        [ 22.994, -32.203, 206.763],\n",
       "        [ 21.994, -31.766, 206.186]], dtype=float32),\n",
       " array([[ 23.54 , -33.38 , 206.471],\n",
       "        [ 22.989, -34.271, 205.461],\n",
       "        [ 21.823, -35.034, 206.073],\n",
       "        [ 22.016, -35.833, 206.996]], dtype=float32),\n",
       " array([[ 20.616, -34.752, 205.593],\n",
       "        [ 19.434, -35.471, 206.042],\n",
       "        [ 19.353, -36.814, 205.324],\n",
       "        [ 19.738, -36.941, 204.159]], dtype=float32),\n",
       " array([[ 18.85 , -37.828, 206.019],\n",
       "        [ 18.666, -39.151, 205.436],\n",
       "        [ 17.264, -39.246, 204.842],\n",
       "        [ 16.538, -38.251, 204.745]], dtype=float32),\n",
       " array([[ 16.871, -40.457, 204.445],\n",
       "        [ 15.522, -40.708, 203.952],\n",
       "        [ 14.485, -40.743, 205.071],\n",
       "        [ 13.285, -40.605, 204.809]], dtype=float32),\n",
       " array([[ 14.934, -40.919, 206.307],\n",
       "        [ 14.09 , -40.886, 207.491],\n",
       "        [ 14.56 , -39.722, 208.36 ],\n",
       "        [ 15.35 , -38.883, 207.916]], dtype=float32),\n",
       " array([[ 14.084, -39.663, 209.605],\n",
       "        [ 14.43 , -38.558, 210.499],\n",
       "        [ 15.831, -38.695, 211.095],\n",
       "        [ 15.98 , -38.849, 212.312]], dtype=float32),\n",
       " array([[ 16.863, -38.641, 210.254],\n",
       "        [ 18.242, -38.648, 210.724],\n",
       "        [ 19.026, -37.616, 209.928],\n",
       "        [ 19.428, -37.877, 208.791]], dtype=float32),\n",
       " array([[ 19.234, -36.445, 210.522],\n",
       "        [ 19.969, -35.353, 209.889],\n",
       "        [ 21.374, -35.349, 210.476],\n",
       "        [ 21.639, -34.651, 211.46 ]], dtype=float32),\n",
       " array([[ 22.269, -36.129, 209.876],\n",
       "        [ 23.632, -36.256, 210.367],\n",
       "        [ 24.42 , -35.012, 209.981],\n",
       "        [ 24.587, -34.714, 208.795]], dtype=float32),\n",
       " array([[ 24.885, -34.278, 210.986],\n",
       "        [ 25.683, -33.077, 210.78 ],\n",
       "        [ 27.147, -33.49 , 210.791],\n",
       "        [ 27.682, -33.87 , 211.839]], dtype=float32),\n",
       " array([[ 27.791, -33.416, 209.63 ],\n",
       "        [ 29.186, -33.807, 209.485],\n",
       "        [ 29.999, -32.558, 209.186],\n",
       "        [ 29.709, -31.822, 208.239]], dtype=float32),\n",
       " array([[ 31.003, -32.311, 210.01 ],\n",
       "        [ 31.901, -31.181, 209.815],\n",
       "        [ 32.861, -31.517, 208.684],\n",
       "        [ 33.158, -32.69 , 208.429]], dtype=float32),\n",
       " array([[ 33.346, -30.487, 207.998],\n",
       "        [ 34.314, -30.694, 206.934],\n",
       "        [ 35.7  , -30.953, 207.52 ],\n",
       "        [ 35.937, -30.805, 208.723]], dtype=float32),\n",
       " array([[ 36.628, -31.331, 206.646],\n",
       "        [ 37.983, -31.634, 207.054],\n",
       "        [ 38.837, -30.393, 207.234],\n",
       "        [ 38.347, -29.261, 207.266]], dtype=float32),\n",
       " array([[ 40.143, -30.618, 207.359],\n",
       "        [ 41.089, -29.529, 207.576],\n",
       "        [ 41.306, -28.776, 206.269],\n",
       "        [ 41.71 , -29.366, 205.262]], dtype=float32),\n",
       " array([[ 41.042, -27.47 , 206.285],\n",
       "        [ 41.178, -26.626, 205.107],\n",
       "        [ 42.556, -25.99 , 204.985],\n",
       "        [ 42.735, -25.085, 204.161]], dtype=float32),\n",
       " array([[ 43.518, -26.432, 205.799],\n",
       "        [ 44.873, -25.892, 205.734],\n",
       "        [ 45.582, -26.332, 204.46 ],\n",
       "        [ 46.422, -25.6  , 203.922]], dtype=float32),\n",
       " array([[ 45.265, -27.534, 203.97 ],\n",
       "        [ 45.757, -27.963, 202.673],\n",
       "        [ 45.189, -27.18 , 201.51 ],\n",
       "        [ 45.93 , -26.829, 200.587]], dtype=float32),\n",
       " array([[ 43.886, -26.89 , 201.54 ],\n",
       "        [ 43.279, -26.027, 200.536],\n",
       "        [ 43.745, -24.584, 200.655],\n",
       "        [ 43.845, -23.894, 199.635]], dtype=float32),\n",
       " array([[ 44.028, -24.121, 201.872],\n",
       "        [ 44.663, -22.827, 202.077],\n",
       "        [ 46.088, -22.78 , 201.545],\n",
       "        [ 46.502, -21.732, 201.025]], dtype=float32),\n",
       " array([[ 46.849, -23.871, 201.665],\n",
       "        [ 48.16 , -23.943, 201.029],\n",
       "        [ 48.031, -23.995, 199.514],\n",
       "        [ 48.875, -23.448, 198.796]], dtype=float32),\n",
       " array([[ 46.981, -24.651, 199.014],\n",
       "        [ 46.671, -24.661, 197.593],\n",
       "        [ 46.25 , -23.297, 197.069],\n",
       "        [ 46.522, -22.988, 195.905]], dtype=float32),\n",
       " array([[ 45.601, -22.476, 197.892],\n",
       "        [ 45.287, -21.106, 197.52 ],\n",
       "        [ 46.408, -20.131, 197.845],\n",
       "        [ 46.336, -18.969, 197.431]], dtype=float32),\n",
       " array([[ 47.437, -20.573, 198.563],\n",
       "        [ 48.547, -19.709, 198.955],\n",
       "        [ 49.759, -19.904, 198.05 ],\n",
       "        [ 50.868, -19.469, 198.365]], dtype=float32),\n",
       " array([[ 49.55 , -20.576, 196.921],\n",
       "        [ 50.599, -20.751, 195.926],\n",
       "        [ 50.922, -19.46 , 195.185],\n",
       "        [ 52.094, -19.203, 194.889]], dtype=float32),\n",
       " array([[ 49.913, -18.644, 194.887],\n",
       "        [ 50.119, -17.4  , 194.175],\n",
       "        [ 50.565, -16.239, 195.037],\n",
       "        [ 50.856, -15.158, 194.517]], dtype=float32),\n",
       " array([[ 50.623, -16.436, 196.351],\n",
       "        [ 51.101, -15.409, 197.262],\n",
       "        [ 52.57 , -15.655, 197.595],\n",
       "        [ 53.125, -16.718, 197.301]], dtype=float32),\n",
       " array([[ 53.199, -14.659, 198.212],\n",
       "        [ 54.589, -14.762, 198.633],\n",
       "        [ 54.635, -15.115, 200.113],\n",
       "        [ 54.02 , -14.436, 200.939]], dtype=float32),\n",
       " array([[ 55.36 , -16.179, 200.443],\n",
       "        [ 55.509, -16.594, 201.831],\n",
       "        [ 56.472, -15.651, 202.542],\n",
       "        [ 57.631, -15.51 , 202.143]], dtype=float32),\n",
       " array([[ 55.984, -15.001, 203.593],\n",
       "        [ 56.769, -14.057, 204.373],\n",
       "        [ 57.144, -14.677, 205.713],\n",
       "        [ 56.495, -15.605, 206.201]], dtype=float32),\n",
       " array([[ 58.207, -14.149, 206.311],\n",
       "        [ 58.694, -14.62 , 207.597],\n",
       "        [ 58.148, -13.719, 208.7  ],\n",
       "        [ 57.706, -12.594, 208.453]], dtype=float32),\n",
       " array([[ 58.179, -14.218, 209.933],\n",
       "        [ 57.685, -13.455, 211.075],\n",
       "        [ 58.709, -13.566, 212.191],\n",
       "        [ 58.892, -14.648, 212.757]], dtype=float32),\n",
       " array([[ 59.369, -12.455, 212.506],\n",
       "        [ 60.39 , -12.4  , 213.549],\n",
       "        [ 59.838, -11.833, 214.851],\n",
       "        [ 60.537, -11.134, 215.588]], dtype=float32),\n",
       " array([[ 58.575, -12.125, 215.146],\n",
       "        [ 57.926, -11.587, 216.323],\n",
       "        [ 56.985, -10.458, 215.964],\n",
       "        [ 56.113, -10.62 , 215.104]], dtype=float32),\n",
       " array([[ 57.153,  -9.308, 216.615],\n",
       "        [ 56.396,  -8.11 , 216.283],\n",
       "        [ 56.769,  -7.527, 214.928],\n",
       "        [ 55.931,  -6.873, 214.299]], dtype=float32),\n",
       " array([[ 57.996,  -7.748, 214.466],\n",
       "        [ 58.425,  -7.316, 213.145],\n",
       "        [ 58.468,  -8.523, 212.217],\n",
       "        [ 59.399,  -9.333, 212.286]], dtype=float32),\n",
       " array([[ 57.451,  -8.647, 211.368],\n",
       "        [ 57.439,  -9.659, 210.33 ],\n",
       "        [ 58.468,  -9.374, 209.257],\n",
       "        [ 58.544,  -8.251, 208.747]], dtype=float32),\n",
       " array([[ 59.277, -10.377, 208.926],\n",
       "        [ 60.363, -10.192, 207.972],\n",
       "        [ 59.896, -10.548, 206.566],\n",
       "        [ 59.818, -11.727, 206.207]], dtype=float32),\n",
       " array([[ 59.581,  -9.53 , 205.774],\n",
       "        [ 59.331,  -9.702, 204.352],\n",
       "        [ 60.619,  -9.443, 203.579],\n",
       "        [ 61.194,  -8.353, 203.631]], dtype=float32),\n",
       " array([[ 61.07 , -10.467, 202.856],\n",
       "        [ 62.362, -10.435, 202.182],\n",
       "        [ 62.252, -10.095, 200.701],\n",
       "        [ 63.227, -10.258, 199.962]], dtype=float32),\n",
       " array([[ 61.094,  -9.62 , 200.253],\n",
       "        [ 60.913,  -9.274, 198.851],\n",
       "        [ 60.221,  -7.923, 198.768],\n",
       "        [ 59.627,  -7.447, 199.739]], dtype=float32),\n",
       " array([[ 60.308,  -7.311, 197.595],\n",
       "        [ 59.687,  -6.031, 197.344],\n",
       "        [ 60.502,  -5.233, 196.349],\n",
       "        [ 61.469,  -5.731, 195.771]], dtype=float32),\n",
       " array([[ 60.099,  -3.979, 196.159],\n",
       "        [ 60.77 ,  -3.098, 195.215],\n",
       "        [ 60.506,  -1.657, 195.622],\n",
       "        [ 59.387,  -1.158, 195.482]], dtype=float32),\n",
       " array([[ 61.545,  -1.   , 196.13 ],\n",
       "        [ 61.457,   0.396, 196.523],\n",
       "        [ 62.107,   1.273, 195.453],\n",
       "        [ 62.649,   0.781, 194.46 ]], dtype=float32),\n",
       " array([[ 62.061,   2.59 , 195.649],\n",
       "        [ 62.656,   3.531, 194.7  ],\n",
       "        [ 63.53 ,   4.476, 195.517],\n",
       "        [ 63.017,   5.247, 196.333]], dtype=float32),\n",
       " array([[ 64.839,   4.418, 195.287],\n",
       "        [ 65.815,   5.1  , 196.126],\n",
       "        [ 66.43 ,   6.266, 195.367],\n",
       "        [ 66.752,   6.144, 194.178]], dtype=float32),\n",
       " array([[ 66.586,   7.393, 196.057],\n",
       "        [ 67.34 ,   8.528, 195.549],\n",
       "        [ 68.748,   8.467, 196.128],\n",
       "        [ 68.962,   8.796, 197.298]], dtype=float32),\n",
       " array([[ 69.7  ,   8.043, 195.308],\n",
       "        [ 71.097,   7.91 , 195.702],\n",
       "        [ 71.715,   9.301, 195.63 ],\n",
       "        [ 71.8  ,   9.9  , 194.553]], dtype=float32),\n",
       " array([[ 72.108,   9.821, 196.791],\n",
       "        [ 72.812,  11.094, 196.886],\n",
       "        [ 74.308,  10.811, 196.866],\n",
       "        [ 74.877,  10.36 , 197.865]], dtype=float32),\n",
       " array([[ 74.946,  11.076, 195.727],\n",
       "        [ 76.369,  10.822, 195.548],\n",
       "        [ 77.205,  12.086, 195.703],\n",
       "        [ 78.397,  12.086, 195.38 ]], dtype=float32),\n",
       " array([[ 76.593,  13.174, 196.177],\n",
       "        [ 77.323,  14.415, 196.403],\n",
       "        [ 78.273,  14.314, 197.589],\n",
       "        [ 79.397,  14.824, 197.522]], dtype=float32),\n",
       " array([[ 77.849,  13.667, 198.671],\n",
       "        [ 78.706,  13.446, 199.826],\n",
       "        [ 79.658,  12.273, 199.646],\n",
       "        [ 80.584,  12.117, 200.448]], dtype=float32),\n",
       " array([[ 79.455,  11.449, 198.621],\n",
       "        [ 80.307,  10.294, 198.363],\n",
       "        [ 81.589,  10.781, 197.698],\n",
       "        [ 81.552,  11.351, 196.603]], dtype=float32),\n",
       " array([[ 82.719,  10.556, 198.358],\n",
       "        [ 84.027,  10.935, 197.846],\n",
       "        [ 84.877,   9.691, 197.625],\n",
       "        [ 84.569,   8.601, 198.115]], dtype=float32),\n",
       " array([[ 85.958,   9.865, 196.871],\n",
       "        [ 86.9  ,   8.784, 196.606],\n",
       "        [ 87.955,   8.779, 197.706],\n",
       "        [ 88.847,   9.633, 197.722]], dtype=float32),\n",
       " array([[ 87.845,   7.823, 198.625],\n",
       "        [ 88.774,   7.722, 199.743],\n",
       "        [ 90.104,   7.159, 199.258],\n",
       "        [ 90.137,   6.273, 198.399]], dtype=float32),\n",
       " array([[ 91.198,   7.68 , 199.804],\n",
       "        [ 92.523,   7.233, 199.43 ],\n",
       "        [ 93.   ,   7.703, 198.075],\n",
       "        [ 93.938,   7.112, 197.529]], dtype=float32),\n",
       " array([[ 92.368,   8.735, 197.509],\n",
       "        [ 92.823,   9.298, 196.242],\n",
       "        [ 94.15 ,  10.028, 196.41 ],\n",
       "        [ 95.014,   9.966, 195.529]], dtype=float32),\n",
       " array([[ 94.339,  10.716, 197.536],\n",
       "        [ 95.614,  11.353, 197.831],\n",
       "        [ 96.669,  10.367, 198.309],\n",
       "        [ 97.851,  10.727, 198.35 ]], dtype=float32),\n",
       " array([[ 96.272,   9.152, 198.687],\n",
       "        [ 97.224,   8.105, 199.024],\n",
       "        [ 97.947,   7.643, 197.766],\n",
       "        [ 97.345,   7.517, 196.695]], dtype=float32),\n",
       " array([[ 99.245,   7.393, 197.901],\n",
       "        [100.07 ,   7.059, 196.752],\n",
       "        [ 99.904,   5.591, 196.365],\n",
       "        [ 99.156,   4.83 , 196.985]], dtype=float32),\n",
       " array([[100.617,   5.204, 195.31 ],\n",
       "        [100.6  ,   3.831, 194.835],\n",
       "        [101.368,   2.922, 195.793],\n",
       "        [102.183,   3.371, 196.604]], dtype=float32),\n",
       " array([[101.082,   1.626, 195.698],\n",
       "        [101.755,   0.639, 196.53 ],\n",
       "        [103.184,   0.428, 196.044],\n",
       "        [103.527,   0.748, 194.902]], dtype=float32),\n",
       " array([[ 1.04024e+02, -1.04000e-01,  1.96930e+02],\n",
       "        [ 1.05428e+02, -3.22000e-01,  1.96605e+02],\n",
       "        [ 1.05627e+02, -1.48000e+00,  1.95639e+02],\n",
       "        [ 1.06090e+02, -1.27700e+00,  1.94513e+02]], dtype=float32),\n",
       " array([[105.293,  -2.695, 196.058],\n",
       "        [105.464,  -3.864, 195.207],\n",
       "        [104.815,  -5.061, 195.883],\n",
       "        [104.18 ,  -4.932, 196.934]], dtype=float32),\n",
       " array([[104.984,  -6.23 , 195.263],\n",
       "        [104.567,  -7.512, 195.827],\n",
       "        [103.042,  -7.657, 195.834],\n",
       "        [102.427,  -8.059, 196.821]], dtype=float32),\n",
       " array([[102.441,  -7.307, 194.702],\n",
       "        [101.039,  -7.618, 194.478],\n",
       "        [100.927,  -9.026, 193.903],\n",
       "        [101.191,  -9.26 , 192.721]], dtype=float32),\n",
       " array([[100.539,  -9.979, 194.75 ],\n",
       "        [100.522, -11.383, 194.355],\n",
       "        [ 99.078, -11.84 , 194.243],\n",
       "        [ 98.357, -11.868, 195.244]], dtype=float32),\n",
       " array([[ 98.661, -12.204, 193.034],\n",
       "        [ 97.281, -12.61 , 192.802],\n",
       "        [ 97.059, -14.025, 193.32 ],\n",
       "        [ 97.152, -14.997, 192.565]], dtype=float32),\n",
       " array([[ 96.758, -14.139, 194.611],\n",
       "        [ 96.425, -15.415, 195.227],\n",
       "        [ 94.917, -15.625, 195.192],\n",
       "        [ 94.154, -14.73 , 195.572]], dtype=float32),\n",
       " array([[ 94.49 , -16.821, 194.784],\n",
       "        [ 93.101, -17.057, 194.413],\n",
       "        [ 92.745, -16.2  , 193.204],\n",
       "        [ 91.965, -15.248, 193.316]], dtype=float32),\n",
       " array([[ 93.371, -16.508, 192.068],\n",
       "        [ 93.199, -15.773, 190.81 ],\n",
       "        [ 91.769, -15.939, 190.308],\n",
       "        [ 91.294, -17.075, 190.15 ]], dtype=float32),\n",
       " array([[ 91.053, -14.848, 190.047],\n",
       "        [ 89.615, -14.957, 189.783],\n",
       "        [ 89.3  , -15.019, 188.297],\n",
       "        [ 90.182, -14.934, 187.44 ]], dtype=float32),\n",
       " array([[ 88.011, -15.174, 188.007],\n",
       "        [ 87.486, -15.168, 186.652],\n",
       "        [ 86.239, -14.297, 186.636],\n",
       "        [ 85.994, -13.523, 187.566]], dtype=float32),\n",
       " array([[ 85.464, -14.415, 185.559],\n",
       "        [ 84.219, -13.67 , 185.4  ],\n",
       "        [ 83.183, -14.214, 186.379],\n",
       "        [ 82.942, -15.425, 186.427]], dtype=float32),\n",
       " array([[ 82.584, -13.322, 187.161],\n",
       "        [ 81.64 , -13.713, 188.21 ],\n",
       "        [ 80.195, -13.612, 187.723],\n",
       "        [ 79.337, -12.991, 188.351]], dtype=float32),\n",
       " array([[ 79.932, -14.235, 186.573],\n",
       "        [ 78.575, -14.371, 186.053],\n",
       "        [ 78.058, -13.134, 185.323],\n",
       "        [ 76.926, -13.134, 184.829]], dtype=float32),\n",
       " array([[ 78.867, -12.079, 185.244],\n",
       "        [ 78.456, -10.847, 184.588],\n",
       "        [ 79.555, -10.173, 183.783],\n",
       "        [ 79.327,  -9.071, 183.271]], dtype=float32),\n",
       " array([[ 80.726, -10.787, 183.652],\n",
       "        [ 81.851, -10.184, 182.969],\n",
       "        [ 82.825,  -9.482, 183.886],\n",
       "        [ 83.934,  -9.149, 183.449]], dtype=float32),\n",
       " array([[ 82.451,  -9.244, 185.138],\n",
       "        [ 83.351,  -8.628, 186.097],\n",
       "        [ 84.3  ,  -9.674, 186.667],\n",
       "        [ 83.89 , -10.757, 187.094]], dtype=float32),\n",
       " array([[ 85.585,  -9.334, 186.677],\n",
       "        [ 86.636, -10.234, 187.135],\n",
       "        [ 87.045,  -9.776, 188.526],\n",
       "        [ 87.615,  -8.688, 188.687]], dtype=float32),\n",
       " array([[ 86.759, -10.601, 189.527],\n",
       "        [ 87.091, -10.287, 190.91 ],\n",
       "        [ 88.547, -10.658, 191.151],\n",
       "        [ 88.9  , -11.842, 191.157]], dtype=float32),\n",
       " array([[ 89.391,  -9.65 , 191.347],\n",
       "        [ 90.822,  -9.846, 191.54 ],\n",
       "        [ 91.088,  -9.905, 193.036],\n",
       "        [ 90.89 ,  -8.913, 193.748]], dtype=float32),\n",
       " array([[ 91.538, -11.06 , 193.51 ],\n",
       "        [ 91.948, -11.236, 194.895],\n",
       "        [ 93.468, -11.208, 194.938],\n",
       "        [ 94.127, -12.049, 194.318]], dtype=float32),\n",
       " array([[ 94.021, -10.239, 195.661],\n",
       "        [ 95.458, -10.027, 195.692],\n",
       "        [ 95.944, -10.043, 197.136],\n",
       "        [ 95.189,  -9.807, 198.08 ]], dtype=float32),\n",
       " array([[ 97.225, -10.351, 197.293],\n",
       "        [ 97.923, -10.258, 198.571],\n",
       "        [ 99.035,  -9.242, 198.349],\n",
       "        [100.013,  -9.53 , 197.652]], dtype=float32),\n",
       " array([[ 98.857,  -8.043, 198.894],\n",
       "        [ 99.891,  -7.022, 198.837],\n",
       "        [100.997,  -7.396, 199.813],\n",
       "        [100.833,  -7.265, 201.03 ]], dtype=float32),\n",
       " array([[102.102,  -7.909, 199.279],\n",
       "        [103.284,  -8.235, 200.07 ],\n",
       "        [104.116,  -6.961, 200.153],\n",
       "        [104.861,  -6.627, 199.23 ]], dtype=float32),\n",
       " array([[103.988,  -6.253, 201.264],\n",
       "        [104.684,  -4.994, 201.435],\n",
       "        [104.047,  -4.167, 202.53 ],\n",
       "        [102.855,  -4.287, 202.822]], dtype=float32),\n",
       " array([[ 1.04868e+02, -3.30600e+00,  2.03128e+02],\n",
       "        [ 1.04478e+02, -2.49400e+00,  2.04276e+02],\n",
       "        [ 1.04206e+02, -1.04600e+00,  2.03886e+02],\n",
       "        [ 1.04571e+02, -1.19000e-01,  2.04613e+02]], dtype=float32),\n",
       " array([[103.572,  -0.838, 202.728],\n",
       "        [103.314,   0.511, 202.233],\n",
       "        [102.211,   1.234, 203.   ],\n",
       "        [102.092,   2.458, 202.879]], dtype=float32),\n",
       " array([[101.404,   0.515, 203.779],\n",
       "        [100.353,   1.125, 204.556],\n",
       "        [ 99.174,   1.522, 203.694],\n",
       "        [ 98.426,   0.676, 203.197]], dtype=float32),\n",
       " array([[ 98.987,   2.829, 203.497],\n",
       "        [ 97.919,   3.286, 202.599],\n",
       "        [ 98.389,   3.421, 201.16 ],\n",
       "        [ 98.319,   4.506, 200.575]], dtype=float32),\n",
       " array([[ 98.865,   2.325, 200.58 ],\n",
       "        [ 99.329,   2.285, 199.203],\n",
       "        [ 98.152,   1.994, 198.279],\n",
       "        [ 97.104,   1.504, 198.705]], dtype=float32),\n",
       " array([[ 98.334,   2.303, 196.999],\n",
       "        [ 97.314,   2.084, 195.981],\n",
       "        [ 97.769,   0.948, 195.078],\n",
       "        [ 98.937,   0.897, 194.681]], dtype=float32),\n",
       " array([[ 9.68510e+01,  4.10000e-02,  1.94759e+02],\n",
       "        [ 9.71670e+01, -1.10900e+00,  1.93915e+02],\n",
       "        [ 9.72710e+01, -6.55000e-01,  1.92463e+02],\n",
       "        [ 9.62500e+01, -3.31000e-01,  1.91840e+02]], dtype=float32),\n",
       " array([[ 98.473,  -0.615, 191.886],\n",
       "        [ 98.604,  -0.245, 190.464],\n",
       "        [ 98.423,  -1.445, 189.539],\n",
       "        [ 99.381,  -2.035, 189.03 ]], dtype=float32),\n",
       " array([[ 97.167,  -1.82 , 189.317],\n",
       "        [ 96.822,  -2.978, 188.507],\n",
       "        [ 96.259,  -2.523, 187.169],\n",
       "        [ 95.7  ,  -1.428, 187.054]], dtype=float32),\n",
       " array([[ 96.411,  -3.372, 186.158],\n",
       "        [ 95.919,  -3.071, 184.82 ],\n",
       "        [ 95.465,  -4.372, 184.169],\n",
       "        [ 96.049,  -5.438, 184.387]], dtype=float32),\n",
       " array([[ 94.4  ,  -4.279, 183.381],\n",
       "        [ 93.89 ,  -5.4  , 182.605],\n",
       "        [ 93.874,  -5.009, 181.134],\n",
       "        [ 93.122,  -4.119, 180.726]], dtype=float32),\n",
       " array([[ 94.709,  -5.677, 180.34 ],\n",
       "        [ 94.842,  -5.355, 178.923],\n",
       "        [ 95.29 ,  -6.597, 178.166],\n",
       "        [ 95.954,  -7.471, 178.731]], dtype=float32),\n",
       " array([[ 94.913,  -6.674, 176.891],\n",
       "        [ 95.408,  -7.743, 176.032],\n",
       "        [ 96.829,  -7.434, 175.578],\n",
       "        [ 97.754,  -8.228, 175.784]], dtype=float32),\n",
       " array([[ 97.02 ,  -6.268, 174.965],\n",
       "        [ 98.316,  -5.846, 174.45 ],\n",
       "        [ 99.229,  -5.391, 175.589],\n",
       "        [ 99.052,  -4.321, 176.178]], dtype=float32),\n",
       " array([[100.22 ,  -6.231, 175.892],\n",
       "        [101.186,  -5.918, 176.935],\n",
       "        [102.348,  -5.081, 176.423],\n",
       "        [103.1  ,  -4.521, 177.229]], dtype=float32),\n",
       " array([[102.517,  -4.979, 175.104],\n",
       "        [103.543,  -4.114, 174.537],\n",
       "        [103.109,  -2.656, 174.495],\n",
       "        [103.954,  -1.769, 174.328]], dtype=float32),\n",
       " array([[101.814,  -2.388, 174.645],\n",
       "        [101.317,  -1.019, 174.677],\n",
       "        [101.09 ,  -0.516, 176.093],\n",
       "        [101.476,   0.613, 176.412]], dtype=float32),\n",
       " array([[ 1.00468e+02, -1.32300e+00,  1.76952e+02],\n",
       "        [ 1.00219e+02, -9.54000e-01,  1.78343e+02],\n",
       "        [ 9.90610e+01,  3.90000e-02,  1.78464e+02],\n",
       "        [ 9.89410e+01,  7.83000e-01,  1.79439e+02]], dtype=float32),\n",
       " array([[ 9.82060e+01,  4.10000e-02,  1.77447e+02],\n",
       "        [ 9.70360e+01,  9.03000e-01,  1.77461e+02],\n",
       "        [ 9.59610e+01,  2.98000e-01,  1.78359e+02],\n",
       "        [ 9.59770e+01, -9.11000e-01,  1.78616e+02]], dtype=float32),\n",
       " array([[ 9.50300e+01,  1.10600e+00,  1.78869e+02],\n",
       "        [ 9.39210e+01,  5.43000e-01,  1.79650e+02],\n",
       "        [ 9.29180e+01, -1.62000e-01,  1.78751e+02],\n",
       "        [ 9.25030e+01,  3.76000e-01,  1.77721e+02]], dtype=float32),\n",
       " array([[ 92.531,  -1.375, 179.139],\n",
       "        [ 91.652,  -2.194, 178.312],\n",
       "        [ 90.195,  -2.146, 178.747],\n",
       "        [ 89.305,  -2.097, 177.885]], dtype=float32),\n",
       " array([[ 89.916,  -2.152, 180.046],\n",
       "        [ 88.545,  -2.16 , 180.518],\n",
       "        [ 88.359,  -1.362, 181.79 ],\n",
       "        [ 89.321,  -1.049, 182.496]], dtype=float32),\n",
       " array([[ 87.104,  -1.024, 182.079],\n",
       "        [ 86.76 ,  -0.317, 183.301],\n",
       "        [ 86.852,  -1.258, 184.501],\n",
       "        [ 86.719,  -2.478, 184.383]], dtype=float32),\n",
       " array([[ 87.086,  -0.674, 185.672],\n",
       "        [ 87.244,  -1.431, 186.906],\n",
       "        [ 85.976,  -1.298, 187.734],\n",
       "        [ 85.402,  -0.208, 187.825]], dtype=float32),\n",
       " array([[ 85.536,  -2.412, 188.323],\n",
       "        [ 84.372,  -2.377, 189.205],\n",
       "        [ 84.733,  -1.71 , 190.526],\n",
       "        [ 84.142,  -0.695, 190.914]], dtype=float32),\n",
       " array([[ 85.713,  -2.265, 191.231],\n",
       "        [ 86.259,  -1.625, 192.424],\n",
       "        [ 87.325,  -0.634, 191.974],\n",
       "        [ 88.521,  -0.929, 192.013]], dtype=float32),\n",
       " array([[ 86.888,   0.542, 191.526],\n",
       "        [ 87.814,   1.561, 191.05 ],\n",
       "        [ 88.531,   2.209, 192.228],\n",
       "        [ 87.98 ,   2.302, 193.33 ]], dtype=float32),\n",
       " array([[ 89.754,   2.684, 191.979],\n",
       "        [ 90.636,   3.217, 193.01 ],\n",
       "        [ 91.022,   2.112, 193.985],\n",
       "        [ 90.68 ,   2.185, 195.172]], dtype=float32),\n",
       " array([[ 9.17010e+01,  1.06400e+00,  1.93517e+02],\n",
       "        [ 9.21020e+01, -2.00000e-02,  1.94425e+02],\n",
       "        [ 9.32680e+01,  4.15000e-01,  1.95298e+02],\n",
       "        [ 9.43850e+01,  6.15000e-01,  1.94816e+02]], dtype=float32),\n",
       " array([[ 9.29960e+01,  5.70000e-01,  1.96590e+02],\n",
       "        [ 9.39760e+01,  1.06000e+00,  1.97550e+02],\n",
       "        [ 9.41280e+01,  2.20000e-02,  1.98651e+02],\n",
       "        [ 9.31320e+01, -4.10000e-01,  1.99243e+02]], dtype=float32),\n",
       " array([[ 95.366,  -0.383, 198.914],\n",
       "        [ 95.66 ,  -1.258, 200.044],\n",
       "        [ 95.549,  -0.439, 201.322],\n",
       "        [ 96.088,   0.669, 201.412]], dtype=float32),\n",
       " array([[ 9.48330e+01, -9.75000e-01,  2.02307e+02],\n",
       "        [ 9.45650e+01, -2.67000e-01,  2.03552e+02],\n",
       "        [ 9.54370e+01, -7.24000e-01,  2.04712e+02],\n",
       "        [ 9.57970e+01,  9.30000e-02,  2.05565e+02]], dtype=float32),\n",
       " array([[ 95.778,  -2.009, 204.771],\n",
       "        [ 96.504,  -2.544, 205.915],\n",
       "        [ 97.98 ,  -2.171, 205.848],\n",
       "        [ 98.553,  -2.024, 204.764]], dtype=float32),\n",
       " array([[ 98.592,  -2.015, 207.02 ],\n",
       "        [100.011,  -1.713, 207.133],\n",
       "        [100.856,  -2.941, 207.448],\n",
       "        [102.04 ,  -2.795, 207.77 ]], dtype=float32),\n",
       " array([[100.285,  -4.14 , 207.353],\n",
       "        [100.997,  -5.364, 207.69 ],\n",
       "        [101.896,  -5.809, 206.534],\n",
       "        [102.097,  -5.093, 205.549]], dtype=float32),\n",
       " array([[102.448,  -7.017, 206.658],\n",
       "        [103.349,  -7.527, 205.63 ],\n",
       "        [102.577,  -8.011, 204.408],\n",
       "        [102.751,  -7.483, 203.305]], dtype=float32),\n",
       " array([[101.708,  -9.003, 204.588],\n",
       "        [100.886,  -9.545, 203.508],\n",
       "        [ 99.442,  -9.154, 203.795],\n",
       "        [ 98.822,  -9.685, 204.721]], dtype=float32),\n",
       " array([[ 98.91 ,  -8.225, 203.005],\n",
       "        [ 97.559,  -7.706, 203.199],\n",
       "        [ 96.655,  -8.284, 202.117],\n",
       "        [ 96.862,  -8.029, 200.928]], dtype=float32),\n",
       " array([[ 95.662,  -9.066, 202.528],\n",
       "        [ 94.699,  -9.603, 201.579],\n",
       "        [ 93.676,  -8.537, 201.204],\n",
       "        [ 93.077,  -7.889, 202.067]], dtype=float32),\n",
       " array([[ 93.472,  -8.361, 199.901],\n",
       "        [ 92.526,  -7.373, 199.406],\n",
       "        [ 91.801,  -7.954, 198.204],\n",
       "        [ 92.297,  -8.874, 197.548]], dtype=float32),\n",
       " array([[ 90.613,  -7.423, 197.936],\n",
       "        [ 89.813,  -7.829, 196.791],\n",
       "        [ 89.591,  -6.627, 195.886],\n",
       "        [ 89.125,  -5.577, 196.338]], dtype=float32),\n",
       " array([[ 89.933,  -6.784, 194.613],\n",
       "        [ 89.672,  -5.785, 193.588],\n",
       "        [ 88.697,  -6.37 , 192.569],\n",
       "        [ 88.378,  -7.563, 192.596]], dtype=float32),\n",
       " array([[ 88.225,  -5.523, 191.658],\n",
       "        [ 87.252,  -5.958, 190.665],\n",
       "        [ 87.452,  -5.15 , 189.393],\n",
       "        [ 87.559,  -3.922, 189.446]], dtype=float32),\n",
       " array([[ 87.494,  -5.843, 188.257],\n",
       "        [ 87.65 ,  -5.211, 186.957],\n",
       "        [ 86.697,  -5.856, 185.962],\n",
       "        [ 86.334,  -7.027, 186.096]], dtype=float32),\n",
       " array([[ 86.296,  -5.079, 184.954],\n",
       "        [ 85.365,  -5.528, 183.919],\n",
       "        [ 86.   ,  -5.276, 182.558],\n",
       "        [ 85.804,  -4.206, 181.956]], dtype=float32),\n",
       " array([[ 86.758,  -6.234, 182.029],\n",
       "        [ 87.404,  -6.044, 180.725],\n",
       "        [ 86.452,  -6.374, 179.59 ],\n",
       "        [ 85.263,  -6.646, 179.816]], dtype=float32),\n",
       " array([[ 86.936,  -6.362, 178.351],\n",
       "        [ 86.076,  -6.683, 177.207],\n",
       "        [ 85.821,  -8.182, 177.085],\n",
       "        [ 86.24 ,  -8.992, 177.914]], dtype=float32),\n",
       " array([[ 85.116,  -8.541, 176.012],\n",
       "        [ 84.689,  -9.922, 175.795],\n",
       "        [ 85.88 , -10.768, 175.359],\n",
       "        [ 86.524, -10.487, 174.345]], dtype=float32),\n",
       " array([[ 86.177, -11.804, 176.136],\n",
       "        [ 87.264, -12.708, 175.833],\n",
       "        [ 88.184, -12.871, 177.025],\n",
       "        [ 87.78 , -12.705, 178.176]], dtype=float32),\n",
       " array([[ 89.437, -13.206, 176.733],\n",
       "        [ 90.462, -13.328, 177.761],\n",
       "        [ 91.532, -12.269, 177.528],\n",
       "        [ 91.696, -11.777, 176.407]], dtype=float32),\n",
       " array([[ 92.26 , -11.918, 178.585],\n",
       "        [ 93.278, -10.881, 178.486],\n",
       "        [ 94.338, -11.119, 179.551],\n",
       "        [ 94.325, -12.133, 180.253]], dtype=float32),\n",
       " array([[ 95.26 , -10.164, 179.66 ],\n",
       "        [ 96.355, -10.23 , 180.616],\n",
       "        [ 96.069,  -9.29 , 181.777],\n",
       "        [ 95.632,  -8.152, 181.579]], dtype=float32),\n",
       " array([[ 96.309,  -9.775, 182.992],\n",
       "        [ 96.099,  -8.982, 184.202],\n",
       "        [ 97.468,  -8.752, 184.833],\n",
       "        [ 98.036,  -9.638, 185.477]], dtype=float32),\n",
       " array([[ 98.005,  -7.55 , 184.648],\n",
       "        [ 99.276,  -7.169, 185.256],\n",
       "        [ 98.975,  -6.496, 186.589],\n",
       "        [ 98.464,  -5.372, 186.628]], dtype=float32),\n",
       " array([[ 99.296,  -7.179, 187.685],\n",
       "        [ 99.06 ,  -6.662, 189.028],\n",
       "        [100.382,  -6.13 , 189.56 ],\n",
       "        [101.166,  -6.879, 190.155]], dtype=float32),\n",
       " array([[100.629,  -4.846, 189.344],\n",
       "        [101.869,  -4.228, 189.758],\n",
       "        [102.744,  -3.88 , 188.569],\n",
       "        [102.375,  -4.066, 187.407]], dtype=float32),\n",
       " array([[103.931,  -3.365, 188.879],\n",
       "        [104.922,  -3.01 , 187.872],\n",
       "        [106.07 ,  -4.005, 187.966],\n",
       "        [106.677,  -4.169, 189.03 ]], dtype=float32),\n",
       " array([[106.365,  -4.666, 186.853],\n",
       "        [107.413,  -5.667, 186.819],\n",
       "        [107.013,  -6.965, 187.492],\n",
       "        [105.835,  -7.2  , 187.761]], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"Apos\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248fcab",
   "metadata": {},
   "source": [
    "# test utils.py/get_knearest_epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccc8a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1703c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0\n",
    "K = 48\n",
    "\n",
    "# get k nearest (K = 48)\n",
    "if mode==0:\n",
    "    for i in range(len(data)):\n",
    "        # maintain a heap with k amino acids\n",
    "        epitope = []\n",
    "        Apos = np.hstack(data[i][\"Apos\"])\n",
    "        Aseq = \"\".join(data[i][\"Aseq\"])\n",
    "        for Aidx in range(len(Aseq)):\n",
    "            # traverse heavy/light chain to find nearest distance\n",
    "            nearest_dist = np.inf\n",
    "            for Hidx in range(len(data[i][\"Hpos\"])):\n",
    "                cur_dist = np.sqrt(np.sum((Apos[Aidx][0] - data[i][\"Hpos\"][Hidx][0]) ** 2))\n",
    "                nearest_dist = np.min([cur_dist, nearest_dist])\n",
    "            for Lidx in range(len(data[i][\"Lpos\"])):\n",
    "                cur_dist = np.sqrt(np.sum((Apos[Aidx][0] - data[i][\"Lpos\"][Lidx][0]) ** 2))\n",
    "                nearest_dist = np.min([cur_dist, nearest_dist])\n",
    "\n",
    "            epitope.append((nearest_dist, Aidx))\n",
    "\n",
    "        epitope_heap = heapq.nsmallest(K, epitope, key=lambda x:x[0])\n",
    "        epitope_index = sorted([i[1] for i in epitope_heap])\n",
    "\n",
    "        data[i][\"epitope\"] = \"\".join([aseq[i] for i in epitope_index])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9497b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pdb', 'Hchain', 'Lchain', 'Achain', 'Hseq', 'Lseq', 'Aseq', 'L1', 'L2', 'L3', 'H1', 'H2', 'H3', 'Hpos', 'Lpos', 'Apos', 'epitope'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5222150b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NMEVSCYEASISDFACSKKMTGKLTMNNKHPWHAADTGTPHWMDGAKG'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"epitope\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69842e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open(\"./demo_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80743e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5359"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pickle.load(open(\"./demo_data.pkl\", \"rb\"))\n",
    "len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce62089f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pdb', 'Hchain', 'Lchain', 'Achain', 'Hseq', 'Lseq', 'Aseq', 'L1', 'L2', 'L3', 'H1', 'H2', 'H3', 'Hpos', 'Lpos', 'Apos', 'epitope'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bc4d887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5359"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f15ff7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NMEVSCYEASISDFACSKKMTGKLTMNNKHPWHAADTGTPHWMDGAKG'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aseq = \"\".join(data[i][\"Aseq\"])\n",
    "# epi_index = data[0][\"epitope\"]\n",
    "\n",
    "# \"\".join([aseq[i] for i in epi_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2eda597e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.025998115539551, 120),\n",
       " (4.572774887084961, 122),\n",
       " (4.610614776611328, 279),\n",
       " (4.689812660217285, 123),\n",
       " (4.719902038574219, 125),\n",
       " (4.904451370239258, 121),\n",
       " (5.198207378387451, 233),\n",
       " (5.715717315673828, 232),\n",
       " (5.928899765014648, 204),\n",
       " (5.9649763107299805, 124),\n",
       " (6.015800476074219, 205),\n",
       " (6.222243785858154, 278),\n",
       " (6.478855133056641, 126),\n",
       " (6.5371809005737305, 207),\n",
       " (6.65501070022583, 280),\n",
       " (6.8116655349731445, 206),\n",
       " (6.899214744567871, 119),\n",
       " (7.3167405128479, 231),\n",
       " (7.490304946899414, 127),\n",
       " (7.526638507843018, 234),\n",
       " (7.834255218505859, 235),\n",
       " (7.8423590660095215, 208),\n",
       " (7.913382530212402, 60),\n",
       " (8.017367362976074, 277),\n",
       " (8.02734375, 230),\n",
       " (8.091531753540039, 225),\n",
       " (8.226497650146484, 66),\n",
       " (8.301057815551758, 59),\n",
       " (8.370485305786133, 228),\n",
       " (8.457207679748535, 61),\n",
       " (8.466352462768555, 276),\n",
       " (8.509766578674316, 62),\n",
       " (8.640408515930176, 63),\n",
       " (8.71596622467041, 229),\n",
       " (8.930583953857422, 203),\n",
       " (8.934435844421387, 54),\n",
       " (9.243196487426758, 55),\n",
       " (9.259186744689941, 209),\n",
       " (9.449320793151855, 224),\n",
       " (9.453545570373535, 51),\n",
       " (9.508502960205078, 65),\n",
       " (9.600605964660645, 52),\n",
       " (9.609257698059082, 57),\n",
       " (9.685733795166016, 118),\n",
       " (9.696464538574219, 64),\n",
       " (9.723125457763672, 281),\n",
       " (9.733400344848633, 223),\n",
       " (9.883964538574219, 226)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epitope_heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8077b246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32.8936653137207, 0),\n",
       " (30.107135772705078, 1),\n",
       " (30.423547744750977, 2),\n",
       " (32.810401916503906, 3),\n",
       " (31.96693992614746, 4),\n",
       " (30.500171661376953, 5),\n",
       " (30.18033218383789, 6),\n",
       " (30.703096389770508, 7),\n",
       " (32.23325729370117, 8),\n",
       " (34.15449905395508, 9),\n",
       " (37.3301887512207, 10),\n",
       " (38.003326416015625, 11),\n",
       " (40.524864196777344, 12),\n",
       " (42.45100784301758, 13),\n",
       " (42.081947326660156, 14),\n",
       " (41.65396499633789, 15),\n",
       " (43.87492370605469, 16),\n",
       " (42.427913665771484, 17),\n",
       " (40.55342102050781, 18),\n",
       " (38.62664031982422, 19),\n",
       " (36.73564529418945, 20),\n",
       " (36.21327590942383, 21),\n",
       " (33.63908386230469, 22),\n",
       " (32.01983642578125, 23),\n",
       " (28.799253463745117, 24),\n",
       " (27.46338653564453, 25),\n",
       " (24.877246856689453, 26),\n",
       " (24.013507843017578, 27),\n",
       " (26.24178695678711, 28),\n",
       " (28.833772659301758, 29),\n",
       " (30.73711585998535, 30),\n",
       " (33.57426071166992, 31),\n",
       " (35.20677947998047, 32),\n",
       " (38.42568588256836, 33),\n",
       " (40.62495040893555, 34),\n",
       " (43.51736831665039, 35),\n",
       " (43.81686782836914, 36),\n",
       " (41.41398239135742, 37),\n",
       " (38.78207778930664, 38),\n",
       " (37.57492446899414, 39),\n",
       " (34.60704040527344, 40),\n",
       " (31.649845123291016, 41),\n",
       " (29.454557418823242, 42),\n",
       " (26.379209518432617, 43),\n",
       " (24.349163055419922, 44),\n",
       " (21.455148696899414, 45),\n",
       " (18.648574829101562, 46),\n",
       " (16.345144271850586, 47),\n",
       " (14.10374927520752, 48),\n",
       " (12.349370956420898, 49),\n",
       " (10.996024131774902, 50),\n",
       " (9.453545570373535, 51),\n",
       " (9.600605964660645, 52),\n",
       " (10.421475410461426, 53),\n",
       " (8.934435844421387, 54),\n",
       " (9.243196487426758, 55),\n",
       " (11.164484024047852, 56),\n",
       " (9.609257698059082, 57),\n",
       " (9.88607406616211, 58),\n",
       " (8.301057815551758, 59),\n",
       " (7.913382530212402, 60),\n",
       " (8.457207679748535, 61),\n",
       " (8.509766578674316, 62),\n",
       " (8.640408515930176, 63),\n",
       " (9.696464538574219, 64),\n",
       " (9.508502960205078, 65),\n",
       " (8.226497650146484, 66),\n",
       " (11.405229568481445, 67),\n",
       " (14.535861015319824, 68),\n",
       " (17.27900505065918, 69),\n",
       " (20.26068687438965, 70),\n",
       " (22.62717056274414, 71),\n",
       " (26.046051025390625, 72),\n",
       " (28.976789474487305, 73),\n",
       " (32.05799865722656, 74),\n",
       " (34.403541564941406, 75),\n",
       " (33.02054214477539, 76),\n",
       " (31.583295822143555, 77),\n",
       " (29.380512237548828, 78),\n",
       " (26.186904907226562, 79),\n",
       " (23.416574478149414, 80),\n",
       " (20.4144229888916, 81),\n",
       " (17.48444366455078, 82),\n",
       " (15.176057815551758, 83),\n",
       " (16.693105697631836, 84),\n",
       " (18.08484649658203, 85),\n",
       " (15.720325469970703, 86),\n",
       " (13.12132453918457, 87),\n",
       " (10.527958869934082, 88),\n",
       " (11.194649696350098, 89),\n",
       " (12.588814735412598, 90),\n",
       " (15.739709854125977, 91),\n",
       " (18.913705825805664, 92),\n",
       " (22.210960388183594, 93),\n",
       " (25.566394805908203, 94),\n",
       " (28.96495819091797, 95),\n",
       " (29.47073745727539, 96),\n",
       " (30.24778938293457, 97),\n",
       " (30.887001037597656, 98),\n",
       " (31.55052375793457, 99),\n",
       " (33.5770149230957, 100),\n",
       " (32.67896270751953, 101),\n",
       " (30.347362518310547, 102),\n",
       " (28.89080810546875, 103),\n",
       " (29.854759216308594, 104),\n",
       " (32.7215461730957, 105),\n",
       " (34.95573043823242, 106),\n",
       " (36.33753204345703, 107),\n",
       " (35.45052719116211, 108),\n",
       " (34.59341812133789, 109),\n",
       " (31.521608352661133, 110),\n",
       " (29.12462043762207, 111),\n",
       " (26.423173904418945, 112),\n",
       " (23.07408905029297, 113),\n",
       " (20.369707107543945, 114),\n",
       " (16.999160766601562, 115),\n",
       " (13.979620933532715, 116),\n",
       " (10.806642532348633, 117),\n",
       " (9.685733795166016, 118),\n",
       " (6.899214744567871, 119),\n",
       " (4.025998115539551, 120),\n",
       " (4.904451370239258, 121),\n",
       " (4.572774887084961, 122),\n",
       " (4.689812660217285, 123),\n",
       " (5.9649763107299805, 124),\n",
       " (4.719902038574219, 125),\n",
       " (6.478855133056641, 126),\n",
       " (7.490304946899414, 127),\n",
       " (10.538780212402344, 128),\n",
       " (13.413928031921387, 129),\n",
       " (15.493705749511719, 130),\n",
       " (18.818561553955078, 131),\n",
       " (18.12898063659668, 132),\n",
       " (15.619819641113281, 133),\n",
       " (15.57036018371582, 134),\n",
       " (15.693438529968262, 135),\n",
       " (17.753582000732422, 136),\n",
       " (18.215730667114258, 137),\n",
       " (20.882553100585938, 138),\n",
       " (22.919639587402344, 139),\n",
       " (25.538360595703125, 140),\n",
       " (28.571748733520508, 141),\n",
       " (31.267831802368164, 142),\n",
       " (34.18998336791992, 143),\n",
       " (36.31316375732422, 144),\n",
       " (37.196044921875, 145),\n",
       " (35.90782165527344, 146),\n",
       " (34.89579391479492, 147),\n",
       " (35.091678619384766, 148),\n",
       " (32.618492126464844, 149),\n",
       " (30.91610336303711, 150),\n",
       " (30.523666381835938, 151),\n",
       " (28.389612197875977, 152),\n",
       " (27.010366439819336, 153),\n",
       " (24.23473358154297, 154),\n",
       " (22.67915916442871, 155),\n",
       " (21.635820388793945, 156),\n",
       " (22.038564682006836, 157),\n",
       " (22.401805877685547, 158),\n",
       " (24.335603713989258, 159),\n",
       " (26.330232620239258, 160),\n",
       " (28.563674926757812, 161),\n",
       " (30.051355361938477, 162),\n",
       " (28.358566284179688, 163),\n",
       " (25.40688133239746, 164),\n",
       " (22.234867095947266, 165),\n",
       " (21.535913467407227, 166),\n",
       " (19.45309066772461, 167),\n",
       " (19.701358795166016, 168),\n",
       " (19.492305755615234, 169),\n",
       " (19.752241134643555, 170),\n",
       " (20.314373016357422, 171),\n",
       " (21.256271362304688, 172),\n",
       " (23.687347412109375, 173),\n",
       " (25.928482055664062, 174),\n",
       " (26.666229248046875, 175),\n",
       " (27.40791893005371, 176),\n",
       " (27.88347816467285, 177),\n",
       " (28.80330467224121, 178),\n",
       " (30.680282592773438, 179),\n",
       " (31.77499008178711, 180),\n",
       " (35.188560485839844, 181),\n",
       " (35.86451721191406, 182),\n",
       " (35.62766647338867, 183),\n",
       " (34.14277267456055, 184),\n",
       " (31.85676383972168, 185),\n",
       " (31.612579345703125, 186),\n",
       " (29.169692993164062, 187),\n",
       " (29.10431671142578, 188),\n",
       " (27.551698684692383, 189),\n",
       " (26.90863800048828, 190),\n",
       " (24.42596435546875, 191),\n",
       " (24.319190979003906, 192),\n",
       " (26.207962036132812, 193),\n",
       " (25.189245223999023, 194),\n",
       " (23.822500228881836, 195),\n",
       " (23.06110191345215, 196),\n",
       " (20.71251678466797, 197),\n",
       " (19.878082275390625, 198),\n",
       " (19.712129592895508, 199),\n",
       " (17.51925277709961, 200),\n",
       " (14.040663719177246, 201),\n",
       " (10.79357624053955, 202),\n",
       " (8.930583953857422, 203),\n",
       " (5.928899765014648, 204),\n",
       " (6.015800476074219, 205),\n",
       " (6.8116655349731445, 206),\n",
       " (6.5371809005737305, 207),\n",
       " (7.8423590660095215, 208),\n",
       " (9.259186744689941, 209),\n",
       " (10.480342864990234, 210),\n",
       " (13.1421537399292, 211),\n",
       " (13.765156745910645, 212),\n",
       " (16.304162979125977, 213),\n",
       " (17.249528884887695, 214),\n",
       " (18.585186004638672, 215),\n",
       " (17.965681076049805, 216),\n",
       " (15.237318992614746, 217),\n",
       " (15.55078125, 218),\n",
       " (17.079334259033203, 219),\n",
       " (15.993749618530273, 220),\n",
       " (16.021955490112305, 221),\n",
       " (13.104086875915527, 222),\n",
       " (9.733400344848633, 223),\n",
       " (9.449320793151855, 224),\n",
       " (8.091531753540039, 225),\n",
       " (9.883964538574219, 226),\n",
       " (11.567763328552246, 227),\n",
       " (8.370485305786133, 228),\n",
       " (8.71596622467041, 229),\n",
       " (8.02734375, 230),\n",
       " (7.3167405128479, 231),\n",
       " (5.715717315673828, 232),\n",
       " (5.198207378387451, 233),\n",
       " (7.526638507843018, 234),\n",
       " (7.834255218505859, 235),\n",
       " (10.122055053710938, 236),\n",
       " (12.726693153381348, 237),\n",
       " (11.41963005065918, 238),\n",
       " (12.621941566467285, 239),\n",
       " (14.031518936157227, 240),\n",
       " (13.088203430175781, 241),\n",
       " (13.62352180480957, 242),\n",
       " (16.796321868896484, 243),\n",
       " (18.9366397857666, 244),\n",
       " (19.583168029785156, 245),\n",
       " (22.18996238708496, 246),\n",
       " (23.301010131835938, 247),\n",
       " (26.080963134765625, 248),\n",
       " (26.7711238861084, 249),\n",
       " (25.311206817626953, 250),\n",
       " (22.846942901611328, 251),\n",
       " (20.649641036987305, 252),\n",
       " (18.294677734375, 253),\n",
       " (15.656322479248047, 254),\n",
       " (14.410231590270996, 255),\n",
       " (12.418840408325195, 256),\n",
       " (13.730405807495117, 257),\n",
       " (13.784884452819824, 258),\n",
       " (11.37762451171875, 259),\n",
       " (13.161130905151367, 260),\n",
       " (13.184606552124023, 261),\n",
       " (13.937767028808594, 262),\n",
       " (16.525230407714844, 263),\n",
       " (15.265366554260254, 264),\n",
       " (14.995280265808105, 265),\n",
       " (17.680662155151367, 266),\n",
       " (17.93102264404297, 267),\n",
       " (16.59087562561035, 268),\n",
       " (18.268234252929688, 269),\n",
       " (19.96525001525879, 270),\n",
       " (18.474470138549805, 271),\n",
       " (17.350160598754883, 272),\n",
       " (16.068679809570312, 273),\n",
       " (13.564882278442383, 274),\n",
       " (11.604557037353516, 275),\n",
       " (8.466352462768555, 276),\n",
       " (8.017367362976074, 277),\n",
       " (6.222243785858154, 278),\n",
       " (4.610614776611328, 279),\n",
       " (6.65501070022583, 280),\n",
       " (9.723125457763672, 281),\n",
       " (11.58193302154541, 282),\n",
       " (14.527958869934082, 283),\n",
       " (16.967979431152344, 284),\n",
       " (19.537565231323242, 285),\n",
       " (22.597728729248047, 286),\n",
       " (25.22651481628418, 287),\n",
       " (26.291963577270508, 288),\n",
       " (28.04471778869629, 289),\n",
       " (29.64854621887207, 290),\n",
       " (30.865650177001953, 291),\n",
       " (32.78132629394531, 292),\n",
       " (33.532196044921875, 293),\n",
       " (36.23052215576172, 294),\n",
       " (37.8831901550293, 295),\n",
       " (37.24195861816406, 296),\n",
       " (36.90041732788086, 297),\n",
       " (38.553993225097656, 298),\n",
       " (41.05847930908203, 299),\n",
       " (40.30952072143555, 300),\n",
       " (42.003387451171875, 301),\n",
       " (44.525611877441406, 302),\n",
       " (46.81976318359375, 303),\n",
       " (47.016963958740234, 304),\n",
       " (49.041595458984375, 305),\n",
       " (50.69588851928711, 306),\n",
       " (49.887088775634766, 307),\n",
       " (51.357913970947266, 308),\n",
       " (52.4165153503418, 309),\n",
       " (52.139930725097656, 310),\n",
       " (50.18691635131836, 311),\n",
       " (48.32488250732422, 312),\n",
       " (47.01859664916992, 313),\n",
       " (44.25144577026367, 314),\n",
       " (41.82415008544922, 315),\n",
       " (42.40894317626953, 316),\n",
       " (42.04271697998047, 317),\n",
       " (41.08916473388672, 318),\n",
       " (41.25967788696289, 319),\n",
       " (38.47398376464844, 320),\n",
       " (37.169761657714844, 321),\n",
       " (38.17333984375, 322),\n",
       " (40.7840461730957, 323),\n",
       " (41.03346633911133, 324),\n",
       " (41.771671295166016, 325),\n",
       " (40.21825408935547, 326),\n",
       " (41.222389221191406, 327),\n",
       " (41.210426330566406, 328),\n",
       " (42.326778411865234, 329),\n",
       " (44.26134490966797, 330),\n",
       " (44.912071228027344, 331),\n",
       " (47.56499099731445, 332),\n",
       " (48.48881912231445, 333),\n",
       " (48.89263153076172, 334),\n",
       " (48.29370880126953, 335),\n",
       " (46.238616943359375, 336),\n",
       " (44.83699417114258, 337),\n",
       " (45.83986282348633, 338),\n",
       " (47.143310546875, 339),\n",
       " (46.62224197387695, 340),\n",
       " (49.436824798583984, 341),\n",
       " (49.820335388183594, 342),\n",
       " (51.14291763305664, 343),\n",
       " (51.493568420410156, 344),\n",
       " (53.24538803100586, 345),\n",
       " (55.47737503051758, 346),\n",
       " (58.32329177856445, 347),\n",
       " (59.83888244628906, 348),\n",
       " (62.296348571777344, 349),\n",
       " (62.87572479248047, 350),\n",
       " (60.786766052246094, 351),\n",
       " (59.16466522216797, 352),\n",
       " (56.2921142578125, 353),\n",
       " (54.09754943847656, 354),\n",
       " (51.62150192260742, 355),\n",
       " (48.6854362487793, 356),\n",
       " (45.88752746582031, 357),\n",
       " (42.552059173583984, 358),\n",
       " (40.467350006103516, 359),\n",
       " (41.654144287109375, 360),\n",
       " (43.83322525024414, 361),\n",
       " (43.72928237915039, 362),\n",
       " (42.6860237121582, 363),\n",
       " (43.0479850769043, 364),\n",
       " (40.77461624145508, 365),\n",
       " (40.27528381347656, 366),\n",
       " (41.95745849609375, 367),\n",
       " (43.044063568115234, 368),\n",
       " (44.98289108276367, 369),\n",
       " (44.916290283203125, 370),\n",
       " (43.02830123901367, 371),\n",
       " (40.309730529785156, 372),\n",
       " (39.78658676147461, 373),\n",
       " (38.651344299316406, 374),\n",
       " (40.30867385864258, 375),\n",
       " (41.28263854980469, 376),\n",
       " (43.12870788574219, 377),\n",
       " (44.88361740112305, 378),\n",
       " (46.83837127685547, 379),\n",
       " (49.64982986450195, 380),\n",
       " (49.85857391357422, 381),\n",
       " (49.54690933227539, 382),\n",
       " (50.67967224121094, 383),\n",
       " (51.28120040893555, 384),\n",
       " (52.888309478759766, 385),\n",
       " (51.48709487915039, 386),\n",
       " (52.27365493774414, 387),\n",
       " (51.60432052612305, 388),\n",
       " (52.01816177368164, 389),\n",
       " (55.074119567871094, 390),\n",
       " (58.06839370727539, 391)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epitope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
